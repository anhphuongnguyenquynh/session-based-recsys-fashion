{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCXlB4ATo5ov"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4h4PLM3Zo5ov"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import math\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from keras.layers import StringLookup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random"
      ],
      "metadata": {
        "id": "1mNPSE1_nWzg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras-core\n",
        "import keras_core as keras_core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPCd3TEHp9p5",
        "outputId": "97c90ef1-cd56-43c6-8d42-2e0a35d6b3bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade keras\n",
        "from keras import ops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8kw5LKsrNSY",
        "outputId": "97ce796e-4c30-48dc-c058-dee292e3b2d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.3.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBxgnpmwo5ow"
      },
      "source": [
        "## Prepare the data\n",
        "\n",
        "### Download and prepare the DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/anhphuongnguyenquynh/session-based-recsys-fashion/main/dressipi_recsys2022_datasets.zip'\n",
        "!wget $url\n",
        "!unzip dressipi_recsys2022_datasets.zip"
      ],
      "metadata": {
        "id": "0BA7xB3y6y96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7660433-2155-4a78-eae5-16779910f69a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-26 15:58:03--  https://raw.githubusercontent.com/anhphuongnguyenquynh/session-based-recsys-fashion/main/dressipi_recsys2022_datasets.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 79384785 (76M) [application/zip]\n",
            "Saving to: ‘dressipi_recsys2022_datasets.zip’\n",
            "\n",
            "dressipi_recsys2022 100%[===================>]  75.71M   317MB/s    in 0.2s    \n",
            "\n",
            "2024-05-26 15:58:04 (317 MB/s) - ‘dressipi_recsys2022_datasets.zip’ saved [79384785/79384785]\n",
            "\n",
            "Archive:  dressipi_recsys2022_datasets.zip\n",
            "   creating: dressipi_recsys2022_dataset/\n",
            "  inflating: dressipi_recsys2022_dataset/README.txt  \n",
            "  inflating: dressipi_recsys2022_dataset/candidate_items.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/item_features.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/test_final_purchases.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/test_final_sessions.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/test_full_purchases.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/test_full_sessions.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/test_leaderboard_purchases.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/test_leaderboard_sessions.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/train_purchases.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/train_sessions.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "item_features = pd.read_csv('dressipi_recsys2022_dataset/item_features.csv')"
      ],
      "metadata": {
        "id": "peLs3xFV61Ao"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_items = pd.read_csv('dressipi_recsys2022_dataset/candidate_items.csv')"
      ],
      "metadata": {
        "id": "l5H-D-3JDrHA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://raw.githubusercontent.com/anhphuongnguyenquynh/session-based-recsys-fashion/main/dataset_filtered/train_sessions_duration003.csv'\n",
        "#train_session fraction 10% ~ 500.000\n",
        "url01 = 'https://raw.githubusercontent.com/anhphuongnguyenquynh/session-based-recsys-fashion/main/dataset_filtered/train_session01_seq.csv'"
      ],
      "metadata": {
        "id": "Up90vpHf64Cp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset01 = pd.read_csv(url01, index_col = 0, parse_dates=[\"date\"])\n",
        "dataset01 = dataset01.dropna()\n",
        "dataset01 = dataset01.reset_index()\n",
        "#fraction\n",
        "dataset = dataset01.sample(frac=0.6)"
      ],
      "metadata": {
        "id": "tDf2bVNb66W1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.dtypes"
      ],
      "metadata": {
        "id": "pexY7_oQUGp1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9cf676f-cb94-4144-c908-31409867982c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "session_id           float64\n",
              "item_id              float64\n",
              "date          datetime64[ns]\n",
              "timestamp            float64\n",
              "month                float64\n",
              "weekYear             float64\n",
              "season               float64\n",
              "duration             float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYXdoCahiecg",
        "outputId": "efcbc8df-0cef-4a23-8e55-01a6d5912c9d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(310166, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Group by session_id after sort_values by timestamp\n",
        "sessions_groups = dataset.sort_values(by=[\"timestamp\"]).groupby(\"session_id\")\n",
        "sessions_train = pd.DataFrame(data = {\n",
        "        \"session_id\": list(sessions_groups.groups.keys()),\n",
        "        \"month\" : list(sessions_groups.month.unique().explode()),\n",
        "        \"weekYear\" : list(sessions_groups.weekYear.unique().explode()),\n",
        "        \"season\" : list(sessions_groups.season.unique().explode()),\n",
        "        \"item_ids\": list(sessions_groups.item_id.apply(list)),\n",
        "        \"durations\": list(sessions_groups.duration.apply(list)),\n",
        "        \"timestamps\": list(sessions_groups.timestamp.apply(list)),\n",
        "    })"
      ],
      "metadata": {
        "id": "GvjwV7G56-WG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop session has item_ids <2\n",
        "sessions_train = sessions_train[sessions_train.item_ids.apply(len) >= 2]"
      ],
      "metadata": {
        "id": "MxNWNWh57FOJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 4\n",
        "step = 2\n",
        "def create_sequences(values, sequence, step):\n",
        "  start_idx = 0\n",
        "  sec_list = []\n",
        "  #Handle case < sequence:\n",
        "  if len(values) < sequence:\n",
        "    values = values * 2\n",
        "  #Handle case >= sequence:\n",
        "  while True:\n",
        "    end_idx = start_idx + sequence\n",
        "    sec = values[start_idx:end_idx]\n",
        "    start_idx += step\n",
        "    if end_idx >= len(values):\n",
        "      sec = values[-sequence:]\n",
        "      sec_list.append(sec)\n",
        "      break\n",
        "    sec_list.append(sec)\n",
        "  return sec_list"
      ],
      "metadata": {
        "id": "mQrh15Th7I6V"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sessions_train[\"item_ids\"] = sessions_train[\"item_ids\"].apply(\n",
        "    lambda values: create_sequences(\n",
        "        values,sequence_length, step))\n",
        "\n",
        "sessions_train[\"durations\"] = sessions_train[\"durations\"].apply(\n",
        "    lambda values: create_sequences(\n",
        "        values,sequence_length, step))\n",
        "\n",
        "sessions_train = sessions_train.drop(columns = [\"timestamps\"])\n",
        "\n",
        "sessions_train = sessions_train.explode(column=[\"item_ids\", \"durations\"]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "ux28h7Gz7NEu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove '[' ']' in a sequence\n",
        "sessions_train.item_ids = sessions_train.item_ids.apply(\n",
        "    lambda x: \",\".join([str(v) for v in x]))\n",
        "\n",
        "sessions_train.durations = sessions_train.durations.apply(\n",
        "    lambda x: \",\".join([str(v) for v in x]))\n"
      ],
      "metadata": {
        "id": "Ik6mlbQH7Z9u"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop weekYear and season\n",
        "#convert type column month to string\n",
        "sessions_train[\"month\"] = sessions_train[\"month\"].astype(str)\n",
        "sessions_train = sessions_train.drop(columns = [\"weekYear\", \"season\"])\n",
        "sessions_train.head(5)"
      ],
      "metadata": {
        "id": "616E3kW18Fnv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "6820cf2f-7d72-4955-c2d7-df922f2cc5ec"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   session_id month                         item_ids          durations\n",
              "0        19.0  11.0    20033.0,6704.0,20033.0,6704.0    1.0,1.0,1.0,1.0\n",
              "1       108.0   6.0  13885.0,26130.0,13885.0,26130.0  1.0,67.0,1.0,67.0\n",
              "2       154.0   4.0  21152.0,27613.0,21152.0,27613.0    1.0,1.0,1.0,1.0\n",
              "3       428.0  11.0    1720.0,14376.0,1720.0,14376.0    1.0,1.0,1.0,1.0\n",
              "4       453.0   8.0  19974.0,11386.0,19974.0,11386.0    1.0,1.0,1.0,1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24fc45e0-e905-4cf6-8a90-255241808c58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session_id</th>\n",
              "      <th>month</th>\n",
              "      <th>item_ids</th>\n",
              "      <th>durations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>20033.0,6704.0,20033.0,6704.0</td>\n",
              "      <td>1.0,1.0,1.0,1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>108.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13885.0,26130.0,13885.0,26130.0</td>\n",
              "      <td>1.0,67.0,1.0,67.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>154.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>21152.0,27613.0,21152.0,27613.0</td>\n",
              "      <td>1.0,1.0,1.0,1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>428.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1720.0,14376.0,1720.0,14376.0</td>\n",
              "      <td>1.0,1.0,1.0,1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>453.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>19974.0,11386.0,19974.0,11386.0</td>\n",
              "      <td>1.0,1.0,1.0,1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24fc45e0-e905-4cf6-8a90-255241808c58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-24fc45e0-e905-4cf6-8a90-255241808c58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-24fc45e0-e905-4cf6-8a90-255241808c58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-99b9c47a-2d76-4158-819c-9af96f6ae23b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-99b9c47a-2d76-4158-819c-9af96f6ae23b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-99b9c47a-2d76-4158-819c-9af96f6ae23b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sessions_train",
              "summary": "{\n  \"name\": \"sessions_train\",\n  \"rows\": 59372,\n  \"fields\": [\n    {\n      \"column\": \"session_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1280327.779757615,\n        \"min\": 19.0,\n        \"max\": 4440001.0,\n        \"num_unique_values\": 49266,\n        \"samples\": [\n          2669848.0,\n          2101862.0,\n          1473990.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"12.0\",\n          \"1.0\",\n          \"11.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"item_ids\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 58558,\n        \"samples\": [\n          \"6187.0,628.0,6187.0,628.0\",\n          \"10537.0,21268.0,10537.0,21268.0\",\n          \"19627.0,3361.0,19627.0,3361.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"durations\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3761,\n        \"samples\": [\n          \"15.0,37.0,15.0,37.0\",\n          \"17.0,1.0,1.0,17.0\",\n          \"11.0,1.0,1.0,12.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sessions_train = sessions_train.rename(columns = {\"item_ids\": \"sequence_item_ids\",\n",
        "                                  \"durations\": \"sequence_durations\"})\n"
      ],
      "metadata": {
        "id": "nQkUKeyr-Vx2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sessions_train.shape"
      ],
      "metadata": {
        "id": "pKocz2zVtXjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5c3abee-f20e-4686-989e-25109f834d35"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59372, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Find similar item by item2vec"
      ],
      "metadata": {
        "id": "j7nfL9EIokPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "n--F2ywEo1Yq"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert to string and store all the sequence_item_ids to a list\n",
        "all_sequence_items = []\n",
        "for i in range(len(sessions_train.index)):\n",
        "  list_seq = list(sessions_train.sequence_item_ids[i].split(\",\"))\n",
        "  all_sequence_items.append(list_seq)"
      ],
      "metadata": {
        "id": "AZP4XJG4om7G"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_sequence_items[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLAoDcmgopqA",
        "outputId": "b5531a0b-d9b9-41ce-95bd-cf483e2db977"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['20033.0', '6704.0', '20033.0', '6704.0'],\n",
              " ['13885.0', '26130.0', '13885.0', '26130.0'],\n",
              " ['21152.0', '27613.0', '21152.0', '27613.0'],\n",
              " ['1720.0', '14376.0', '1720.0', '14376.0']]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_sequence_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HpScdBuotdO",
        "outputId": "ce1b40b9-7e59-4276-d7ab-bf036fae4baa"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59372"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a tokenizer and fit it on the sequence list\n",
        "tok_obj = Tokenizer()\n",
        "tok_obj.fit_on_texts(all_sequence_items)"
      ],
      "metadata": {
        "id": "WDXsS4uTovCH"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create mapping dictionaries for items to ids and ids to items\n",
        "item_to_id = tok_obj.word_index # Example output {'8060.0': 1, '26853.0': 2, '2447.0': 3, '17089.0': 4}\n",
        "id_to_item = {v:k for k, v in item_to_id.items()}"
      ],
      "metadata": {
        "id": "vnPi1rE7o4do"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_ids_list = [[item_to_id[w] for w in sequence] for sequence in all_sequence_items]"
      ],
      "metadata": {
        "id": "38ibLoJbo9R3"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_ids_list[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2K_omLbo-pz",
        "outputId": "4c8384e6-78f7-42ad-be4c-c2ac74d15599"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[728, 967, 728, 967],\n",
              " [7424, 1230, 7424, 1230],\n",
              " [74, 24, 74, 24],\n",
              " [4838, 684, 4838, 684]]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check vocab_size\n",
        "vocab_size = len(item_to_id) + 2\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lEAiPlApAOr",
        "outputId": "4068b8e1-16c4-4e5c-ab73-e09ca54c1860"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15904"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate Skip grams"
      ],
      "metadata": {
        "id": "HNp9eAhEpDZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GENERATE SKIP GRAMS\n",
        "# generate skip-grams\n",
        "skip_grams = [tf.keras.preprocessing.sequence.skipgrams(wid, vocabulary_size=vocab_size) for wid in item_ids_list]\n",
        "# view sample skip-grams\n",
        "pairs, labels = skip_grams[0][0], skip_grams[0][1]"
      ],
      "metadata": {
        "id": "zP_TfSFPpFcW"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(skip_grams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVTzdtwupHEV",
        "outputId": "75c27959-f590-4119-e24e-744d48650dd7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59372"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(4):\n",
        "    print(\"({:s} ({:d}), {:s} ({:d})) -> {:d}\".format(\n",
        "          id_to_item[pairs[i][0]], pairs[i][0],\n",
        "          id_to_item[pairs[i][1]], pairs[i][1],\n",
        "          labels[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J3npUEhpIT9",
        "outputId": "a6e1bade-3964-4158-ae30-5cfceec84dee"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6704.0 (967), 20033.0 (728)) -> 1\n",
            "(6704.0 (967), 6704.0 (967)) -> 1\n",
            "(20033.0 (728), 6608.0 (7397)) -> 0\n",
            "(20033.0 (728), 10454.0 (2962)) -> 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Architectures"
      ],
      "metadata": {
        "id": "Yo1fFyZspTDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 100\n",
        "from tensorflow.keras.layers import Concatenate, Dense, Embedding, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the input layers for the target and context words\n",
        "target_word_input = tf.keras.Input(shape=(1,))\n",
        "context_word_input = tf.keras.Input(shape=(1,))\n",
        "\n",
        "# Build skip-gram architecture\n",
        "target_word_model = Embedding(vocab_size, embedding_size,\n",
        "                              embeddings_initializer=\"glorot_uniform\")(target_word_input)\n",
        "target_word_model = Reshape((embedding_size,))(target_word_model)\n",
        "\n",
        "context_word_model = Embedding(vocab_size, embedding_size,\n",
        "                               embeddings_initializer=\"glorot_uniform\")(context_word_input)\n",
        "context_word_model = Reshape((embedding_size,))(context_word_model)\n",
        "\n",
        "# Concatenate the output of the target and context models\n",
        "merged = Concatenate(axis=1)([target_word_model, context_word_model])\n",
        "\n",
        "# Add a dense layer and sigmoid activation\n",
        "output = Dense(1, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\")(merged)\n",
        "\n",
        "# Define the model\n",
        "model_item2vec = Model(inputs=[target_word_input, context_word_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model_item2vec.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
        "\n",
        "# View model summary\n",
        "print(model_item2vec.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "fobltCjXpOLW",
        "outputId": "708b00fe-cca9-45c5-d03d-c15be46687fc"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │      \u001b[38;5;34m1,590,400\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │      \u001b[38;5;34m1,590,400\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m201\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,590,400</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,590,400</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,181,001\u001b[0m (12.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,181,001</span> (12.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,181,001\u001b[0m (12.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,181,001</span> (12.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skip_grams_train_test = skip_grams[:500]\n",
        "frac_train_test = round(len(skip_grams_train_test)*0.8)"
      ],
      "metadata": {
        "id": "KHVh5TBrpnTa"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frac_train_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_n7s_F3puC0",
        "outputId": "bbfe661e-1cf1-4f14-e6e9-e2ccd2716836"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_skip_grams = skip_grams[:frac_train_test]\n",
        "test_skip_grams = skip_grams[frac_train_test:]"
      ],
      "metadata": {
        "id": "ieyNFW3LpvT4"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAIN THE MODEL\n",
        "# train the model on the skip-grams\n",
        "for epoch in range(1, 4):\n",
        "    total_loss = 0\n",
        "    for i, elem in enumerate(train_skip_grams):\n",
        "        #print('start', i)\n",
        "        skip_first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n",
        "        #print(skip_first_elem, 'skip_first_elem', i)\n",
        "        skip_second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n",
        "        #print(skip_second_elem, 'skip_second_elem', i)\n",
        "        labels = np.array(elem[1], dtype='int32')\n",
        "        #print(labels, 'labels', i)\n",
        "        X = [skip_first_elem, skip_second_elem]\n",
        "        #print(X, 'X', i)\n",
        "        Y = labels\n",
        "        #print(Y, 'Y', i)\n",
        "        if i % 200 == 0:\n",
        "            print('Processed {} skip-gram pairs'.format(i))\n",
        "        total_loss += model_item2vec.train_on_batch(X,Y)\n",
        "        #print(total_loss, 'total_loss', i)\n",
        "\n",
        "    print('Epoch: {} Loss: {}'.format(epoch, total_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJgt3txBpxQe",
        "outputId": "8b9084ab-f00c-4065-8ff5-01089e327d45"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 0 skip-gram pairs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 959 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7bfd19f44c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 960 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7bfd19f44c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 200 skip-gram pairs\n",
            "Epoch: 1 Loss: 99.6143197864294\n",
            "Processed 0 skip-gram pairs\n",
            "Processed 200 skip-gram pairs\n",
            "Epoch: 2 Loss: 85.4210883975029\n",
            "Processed 0 skip-gram pairs\n",
            "Processed 200 skip-gram pairs\n",
            "Epoch: 3 Loss: 59.39291423559189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save model keras\n",
        "model_item2vec.save('model_item2vec.keras')"
      ],
      "metadata": {
        "id": "ZcMWs5Pypzez"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST and EVALUATE THE MODEL\n",
        "# train the model on the skip-grams\n",
        "for epoch in range(1, 2):\n",
        "    total_score = 0\n",
        "    for i, elem in enumerate(test_skip_grams[:100]):\n",
        "        #print('start', i)\n",
        "        skip_first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n",
        "        #print(skip_first_elem, 'skip_first_elem', i)\n",
        "        skip_second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n",
        "        #print(skip_second_elem, 'skip_second_elem', i)\n",
        "        labels = np.array(elem[1], dtype='int32')\n",
        "        #print(labels, 'labels', i)\n",
        "        X = [skip_first_elem, skip_second_elem]\n",
        "        #print(X, 'X', i)\n",
        "        Y = labels\n",
        "        #print(Y, 'Y', i)\n",
        "        if i % 1000 == 0:\n",
        "            print('Processed {} skip-gram pairs'.format(i))\n",
        "        score = model_item2vec.evaluate(X,Y, verbose=0)\n",
        "        total_score += score\n",
        "        #print('Accuracy: %f' % (score*100))\n",
        "\n",
        "    #average score\n",
        "    score = total_score/100\n",
        "    print('Epoch: {} Score: {}'.format(epoch, score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r7qrx3wp1po",
        "outputId": "bb839a0b-8bce-452c-a9f8-27e94396924b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 0 skip-gram pairs\n",
            "Epoch: 1 Loss: 0.316150251571089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get word embeddings to find similar items"
      ],
      "metadata": {
        "id": "6kWTtehjqgmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GET WORD EMBEDDINGS\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "# get the embeddings for the words in the vocabulary\n",
        "#weights = model.layers[2].get_weights()[0]\n",
        "\n",
        "embeddings = model_item2vec.layers[2].get_weights()[0]\n",
        "\n",
        "\n",
        "# `embeddings` has a shape of (num_vocab, embedding_dim)\n",
        "\n",
        "# `word_to_index` is a mapping (i.e. dict) from words to their index, e.g. `love`: 69\n",
        "words_embeddings = {w:embeddings[idx] for w, idx in item_to_id.items()}"
      ],
      "metadata": {
        "id": "7-zltVYZqi5Q"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-sTHjj0qkyI",
        "outputId": "01eb0887-780d-4333-9473-fb665ea1bd5c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15904, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distance_matrix = euclidean_distances(embeddings)"
      ],
      "metadata": {
        "id": "PDI5qgvIql7i"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distance_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKl0L9eFqnDZ",
        "outputId": "558a645f-a2ae-47a8-dd79-66090b482195"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15904, 15904)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def similar_item(item):\n",
        "    list = []\n",
        "    try:\n",
        "        similar_items = {search_term: [id_to_item[idx] for idx in distance_matrix[item_to_id[search_term]-1].argsort()[1:11]+1]\n",
        "                       for search_term in [item]}\n",
        "        list = similar_items[item]\n",
        "    except KeyError:\n",
        "        pass\n",
        "    return list"
      ],
      "metadata": {
        "id": "PiXSJcGtqoTc"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_list_example = similar_item('1890.0')\n",
        "print(similar_list_example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYghLcLvqpp6",
        "outputId": "161a6075-d21f-4506-8175-f5bcc697d631"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['13393.0', '4211.0', '25191.0', '11980.0', '20117.0', '26802.0', '3460.0', '24708.0', '22075.0', '4740.0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DATA AUGMENTATION"
      ],
      "metadata": {
        "id": "AYFb1LkFeKxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "x17xR00mCCXP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Synonym Replacement\n",
        "##Randomly choose an item in a sequence and replace it by a similar item\n",
        "def aug_edaSR(seq):\n",
        "  ##seq: item viewed in sequence\n",
        "  ##n: the number of times the process has to be repeated\n",
        "  ##itemList: danh sách unique các item - tương ứng với negative sample\n",
        "  ##List ra các item có trong seq này, thay thế random 1 item trong chuỗi bằng 1 random bất kì trong item này nhưng không phải là chính nó.\n",
        "\n",
        "  #convert string to list\n",
        "  def stringToListConvert(string):\n",
        "    li = list(string.split(\",\"))\n",
        "    return li\n",
        "  #convert string to list\n",
        "  seqList = stringToListConvert(seq)\n",
        "\n",
        "  randomIndex = random.choice(range(len(seqList)))\n",
        "  #find a similar item of seq(randomIndex)\n",
        "  list_similarItem = similar_item(seqList[randomIndex])\n",
        "\n",
        "  #if list_similarItem is null -> pass\n",
        "  if len(list_similarItem) > 0:\n",
        "      #replace an item in seq by an item in list_similarItem\n",
        "      itemReplace = random.choice(list_similarItem[:5]) #random in top 5\n",
        "      while itemReplace != seqList[randomIndex]:\n",
        "        seqList[randomIndex] = itemReplace\n",
        "      else:\n",
        "        itemReplace = random.choice(list_similarItem)\n",
        "  else:\n",
        "    pass\n",
        "  ##convert seq list to string\n",
        "  seqList = list(map(str, seqList))\n",
        "  seqString = ','.join(seqList)\n",
        "  return seqString"
      ],
      "metadata": {
        "id": "VZXClcnU-1q1"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Synonym Replacement function\n",
        "seqTest = '4816.0,26130.0,4816.0,26130.0'\n",
        "#itemList = [111,222,333,444,555,12,22,32,42,52]\n",
        "aug_edaSR(seqTest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MoD4_o1KqvaL",
        "outputId": "41245b59-5a84-47a4-fa23-d72fdd2dbf2a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4816.0,26130.0,27942.0,26130.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildAugDatasetRS(dataTrain, nAug, fraction, augMethod):\n",
        "  #get fraction of dataset for augmentation: fraction*dataset for augmentation, the rest is remain\n",
        "  ##dataFrac= dataTrain.sample(frac=fraction)\n",
        "  leftFrac, rightFrac = train_test_split(dataTrain, random_state = 104, test_size = fraction, shuffle = True)\n",
        "  #with every session in split_dataTrain -> Generate (N_aug-1) more session like that with one item swap/ random in aug strategy\n",
        "  rightFracLen = len(rightFrac.index)\n",
        "  ##print('check n',rightFracLen)\n",
        "  for i in range (rightFracLen):\n",
        "    currentRow = rightFrac.iloc[i]\n",
        "    ##print('check currentRow', currentRow)\n",
        "    for j in range (nAug-1):\n",
        "      duplicateRow = currentRow.copy()\n",
        "      duplicateRow['sequence_item_ids'] = augMethod(duplicateRow['sequence_item_ids'])\n",
        "      ##add row to rightFrac\n",
        "      rightFrac = pd.concat([rightFrac, duplicateRow.to_frame().T], ignore_index=True)\n",
        "      ##print('check rightFrac', rightFrac)\n",
        "\n",
        "  #check again\n",
        "  #after augment the fraction*dataset, boost the number of input dataset => combine with the rest\n",
        "  dataAug = pd.concat([rightFrac, leftFrac], ignore_index = True, sort = False)\n",
        "\n",
        "  return dataAug"
      ],
      "metadata": {
        "id": "-V3fGK_2-6v2"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Split (85%)"
      ],
      "metadata": {
        "id": "5NSR-DGTezbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dfAug = sessions_train"
      ],
      "metadata": {
        "id": "gN8Izpeb-2qB"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sessions_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTWavg1fyJTV",
        "outputId": "3db8db0d-3370-4f18-e570-01c7722cdd11"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(59372, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_selection = np.random.rand(len(sessions_train.index)) <= 0.85\n",
        "train_data = sessions_train[random_selection]\n",
        "test_data = sessions_train[~random_selection]"
      ],
      "metadata": {
        "id": "xhwoPuAu8QPI"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpRM4Q8WxyIS",
        "outputId": "8c693530-5f2d-4231-a21d-73a5597d3d40"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50621, 4)\n",
            "(8751, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfAug = buildAugDatasetRS(train_data, 2, 0.4, aug_edaSR)"
      ],
      "metadata": {
        "id": "clHyi7A2vu6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = dfAug"
      ],
      "metadata": {
        "id": "_aJO4iHqvwdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.to_csv(\"train_data.csv\", index=False, sep=\"|\", header=False)\n",
        "test_data.to_csv(\"test_data.csv\", index=False, sep=\"|\", header=False)"
      ],
      "metadata": {
        "id": "1YCoMpDWXZ0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_train_data = pd.read_csv('train_data.csv')"
      ],
      "metadata": {
        "id": "Xhv9fBSv-m60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_train_data"
      ],
      "metadata": {
        "id": "9EITWmgy9rp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ],
      "metadata": {
        "id": "LAQH_zD2xDB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBqbNsk8o5oz"
      },
      "source": [
        "# Define metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "J2V1frhUo5oz"
      },
      "outputs": [],
      "source": [
        "CSV_HEADER = list(sessions_train.columns)\n",
        "\n",
        "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
        "    \"session_id\": list(sessions_train.session_id.unique()),\n",
        "    \"item_id\": list(item_features.item_id.unique()),\n",
        "    \"item_category\": list(item_features.feature_category_id.unique()),\n",
        "    \"item_category_value\": list(item_features.feature_value_id.unique()),\n",
        "    \"month\": list(sessions_train.month.unique())\n",
        "}\n",
        "\n",
        "OTHER_FEATURES = [\"month\"]\n",
        "\n",
        "ITEM_FEATURES = [\"item_category\", \"item_category_value\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_HEADER"
      ],
      "metadata": {
        "id": "kh2IfDmBWocY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f2fb75a-89d8-4c32-cec8-3ede27ff8cde"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['session_id', 'month', 'sequence_item_ids', 'sequence_durations']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr4Oxvx9o5oz"
      },
      "source": [
        "# Create `tf.data.Dataset` for training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "2eAG7KDYo5oz"
      },
      "outputs": [],
      "source": [
        "def get_dataset_from_csv(csv_file_path, shuffle=False, batch_size=128):\n",
        "    def process(features):\n",
        "        item_ids_string = features[\"sequence_item_ids\"]\n",
        "        sequence_item_ids = tf.strings.split(item_ids_string, \",\").to_tensor()\n",
        "\n",
        "        # The last movie id in the sequence is the target movie.\n",
        "        features[\"target_item_id\"] = sequence_item_ids[:, -1]\n",
        "        features[\"sequence_item_ids\"] = sequence_item_ids[:, :-1]\n",
        "\n",
        "        durations_string = features[\"sequence_durations\"]\n",
        "        sequence_durations = tf.strings.to_number(\n",
        "            tf.strings.split(durations_string, \",\"), tf.dtypes.float32\n",
        "        ).to_tensor()\n",
        "\n",
        "        # The last durations in the sequence is the target for the model to predict.\n",
        "        target = sequence_durations[:, -1]\n",
        "        features[\"sequence_durations\"] = sequence_durations[:, :-1]\n",
        "\n",
        "        return features, target\n",
        "\n",
        "    dataset = tf.data.experimental.make_csv_dataset(\n",
        "        csv_file_path,\n",
        "        batch_size=batch_size,\n",
        "        column_names=CSV_HEADER,\n",
        "        num_epochs=1,\n",
        "        header=False,\n",
        "        field_delim=\"|\",\n",
        "        shuffle=shuffle,\n",
        "    ).map(process)\n",
        "\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = get_dataset_from_csv(\"train_data.csv\", shuffle=True, batch_size=265)"
      ],
      "metadata": {
        "id": "fgheH6C8XgMC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "Lx6MpPcDYBpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10122236-01be-4f49-d20a-dd3ae051ed5a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=(OrderedDict([('session_id', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('month', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('sequence_item_ids', TensorSpec(shape=(None, None), dtype=tf.string, name=None)), ('sequence_durations', TensorSpec(shape=(None, None), dtype=tf.float32, name=None)), ('target_item_id', TensorSpec(shape=(None,), dtype=tf.string, name=None))]), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV-jhvbMo5oz"
      },
      "source": [
        "# Create model inputs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_inputs(): #to transform tensor-like object\n",
        "    return {\n",
        "        \"session_id\": keras.Input(name=\"session_id\", shape=(1,), dtype=\"string\"),\n",
        "        \"sequence_item_ids\": keras.Input(\n",
        "            name=\"sequence_item_ids\", shape=(sequence_length - 1,), dtype=\"string\"\n",
        "        ),\n",
        "        \"target_item_id\": keras.Input(\n",
        "            name=\"target_item_id\", shape=(1,), dtype=\"string\"\n",
        "        ),\n",
        "        \"sequence_durations\": keras.Input(\n",
        "            name=\"sequence_durations\", shape=(sequence_length - 1,), dtype=tf.float32\n",
        "        ),\n",
        "        \"month\": keras.Input(name=\"month\", shape=(1,), dtype=\"string\"),\n",
        "    }"
      ],
      "metadata": {
        "id": "BTLAbMenYJou"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build vocabulary of item features\n",
        "#filter a subset of item_features table just from item from data train\n",
        "dataset = dataset[dataset[\"item_id\"].notnull()]\n",
        "item_features_filtered = item_features.loc[dataset[\"item_id\"]]"
      ],
      "metadata": {
        "id": "bDKFSj0OY21a"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_features_filtered = item_features_filtered.drop(columns = ['feature_value_id'])"
      ],
      "metadata": {
        "id": "FKOsi-aJZgUI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create one-hot encoding for items(feature_category_id)\n",
        "one_hot_item_features_filtered = pd.get_dummies(item_features_filtered, prefix = 'feature_', columns = ['item_id', 'feature_category_id'])"
      ],
      "metadata": {
        "id": "Gm04ec1vaB9T"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_item_features_filtered.info()"
      ],
      "metadata": {
        "id": "6nDjSyq4aF3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69eadfd2-ccf6-4d8c-f21b-a091c0a09b72"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 310166 entries, 13081 to 26381\n",
            "Columns: 1488 entries, feature__2 to feature__73\n",
            "dtypes: bool(1488)\n",
            "memory usage: 442.5 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BYgzavpo5oz"
      },
      "source": [
        "#Encode input features\n",
        "\n",
        "The `encode_input_features` method works as follows:\n",
        "\n",
        "1. Each categorical other feature (month) is encoded using `layers.Embedding`, with embedding\n",
        "dimension equals to the square root of the vocabulary size of the feature.\n",
        "The embeddings of these features are concatenated to form a single input tensor.\n",
        "\n",
        "2. Each item in the item sequence and the target item is encoded `layers.Embedding`,\n",
        "where the dimension size is the square root of the number of items.\n",
        "\n",
        "3. A multi-hot cates vector for each item is concatenated with its embedding vector,\n",
        "and processed using a non-linear `layers.Dense` to output a vector of the same item\n",
        "embedding dimensions.\n",
        "\n",
        "4. A positional embedding is added to each item embedding in the sequence, and then\n",
        "multiplied by its durations from the durations sequence.\n",
        "\n",
        "5. The target item embedding is concatenated to the sequence item embeddings, producing\n",
        "a tensor with the shape of `[batch size, sequence length, embedding size]`, as expected\n",
        "by the attention layer for the transformer architecture.\n",
        "\n",
        "6. The method returns a tuple of two elements:  `encoded_transformer_features` and\n",
        "`encoded_other_features`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "yfLpgwFjo5oz"
      },
      "outputs": [],
      "source": [
        "def encode_input_features(\n",
        "    inputs,\n",
        "    include_session_id=False,\n",
        "    include_other_features=False,\n",
        "    include_item_features=True,\n",
        "):\n",
        "    encoded_transformer_features = []\n",
        "    encoded_other_features = []\n",
        "\n",
        "    other_feature_names = []\n",
        "    if include_session_id:\n",
        "        other_feature_names.append(\"session_id\")\n",
        "    if include_other_features:\n",
        "        other_feature_names.extend(OTHER_FEATURES) #extend to add item in a list of other features\n",
        "\n",
        "    ## Encode other features\n",
        "    for feature_name in other_feature_names:\n",
        "        # Convert the string input values into integer indices.\n",
        "        vocabulary = [str(i) for i in CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]] #add item in a list of other features\n",
        "        print(vocabulary)\n",
        "        idx = StringLookup(vocabulary=vocabulary,\n",
        "                           mask_token=None,\n",
        "                           num_oov_indices=1,\n",
        "                           )(inputs[feature_name])\n",
        "        # Compute embedding dimensions\n",
        "        embedding_dims = int(math.sqrt(len(vocabulary)))\n",
        "        # Create an embedding layer with the specified dimensions.\n",
        "        embedding_encoder = layers.Embedding(\n",
        "            input_dim=len(vocabulary),\n",
        "            output_dim=embedding_dims,\n",
        "            name=f\"{feature_name}_embedding\",\n",
        "        )\n",
        "        # Convert the index values to embedding representations.\n",
        "        encoded_other_features.append(embedding_encoder(idx))\n",
        "\n",
        "    ## Create a single embedding vector for the session features ##Skip\n",
        "    if len(encoded_other_features) > 1:\n",
        "        encoded_other_features = layers.concatenate(encoded_other_features)\n",
        "    elif len(encoded_other_features) == 1:\n",
        "        encoded_other_features = encoded_other_features[0]\n",
        "    else:\n",
        "        encoded_other_features = None\n",
        "\n",
        "    ## Create a item embedding encoder\n",
        "    item_vocabulary = [str(i) for i in CATEGORICAL_FEATURES_WITH_VOCABULARY['item_id']]\n",
        "                      #tf.strings.as_string(CATEGORICAL_FEATURES_WITH_VOCABULARY[\"item_id\"])\n",
        "    item_embedding_dims = int(math.sqrt(len(item_vocabulary)))\n",
        "    #print(item_vocabulary, 'item_vocabulary')\n",
        "    # Create a lookup to convert string values to integer indices.\n",
        "    item_index_lookup = StringLookup(\n",
        "        vocabulary=item_vocabulary,\n",
        "        mask_token=None,\n",
        "        num_oov_indices=1,\n",
        "        name=\"item_index_lookup\",\n",
        "    )\n",
        "    # Create an item embedding layer with the specified dimensions.\n",
        "    item_embedding_encoder = layers.Embedding(\n",
        "        input_dim=len(item_vocabulary),\n",
        "        output_dim=item_embedding_dims,\n",
        "        name=f\"item_embedding\",\n",
        "    )\n",
        "    # Create a vector lookup for item category\n",
        "    #cate_vectors present one-hot-encoding\n",
        "    #input_dim presents a len of unique item_id and output_dim presents a len of unique\n",
        "    cate_vectors = one_hot_item_features_filtered.to_numpy()\n",
        "    # Create a lookup to convert string values to integer indices.\n",
        "    item_cate_lookup = layers.Embedding(\n",
        "        input_dim=cate_vectors.shape[0],\n",
        "        output_dim=cate_vectors.shape[1],\n",
        "        embeddings_initializer=keras.initializers.Constant(cate_vectors),\n",
        "        trainable=False,\n",
        "        name=\"cate_vector\",\n",
        "    )\n",
        "    # Create a processing layer for cate.\n",
        "    item_embedding_dims_embedding_processor = layers.Dense(\n",
        "        units=item_embedding_dims,\n",
        "        activation=\"relu\",\n",
        "        name=\"process_item_embedding_with_cate\",\n",
        "    )\n",
        "\n",
        "    ## Define a function to encode a given item id.\n",
        "    def encode_item(item_id):\n",
        "        # Convert the string input values into integer indices.\n",
        "        item_idx = item_index_lookup(item_id)\n",
        "        # Item embedding\n",
        "        item_embedding = item_embedding_encoder(item_idx)\n",
        "        encoded_item = item_embedding\n",
        "        if include_item_features:\n",
        "            item_cate_vector = item_cate_lookup(item_idx)\n",
        "            encoded_item = item_embedding_dims_embedding_processor (\n",
        "                layers.concatenate([item_embedding, item_cate_vector])\n",
        "            )\n",
        "        return encoded_item\n",
        "\n",
        "    ## Encoding target_item_id\n",
        "    target_item_id = inputs[\"target_item_id\"]\n",
        "    encoded_target_item = encode_item(target_item_id)\n",
        "\n",
        "    ## Encoding sequence item_ids.\n",
        "    sequence_item_ids = inputs[\"sequence_item_ids\"]\n",
        "    encoded_sequence_items = encode_item(sequence_item_ids)\n",
        "    # Create positional embedding.\n",
        "    position_embedding_encoder = layers.Embedding(\n",
        "        input_dim=sequence_length,\n",
        "        output_dim=item_embedding_dims,\n",
        "        name=\"position_embedding\",\n",
        "    )\n",
        "    positions = tf.range(start=0, limit=sequence_length - 1, delta=1)\n",
        "    encodded_positions = position_embedding_encoder(positions)\n",
        "    # Retrieve sequence durations to incorporate them into the encoding of the item.\n",
        "    sequence_durations = inputs[\"sequence_durations\"]\n",
        "    sequence_durations = keras.ops.expand_dims(sequence_durations, -1)\n",
        "    # Add the positional encoding to the item encodings and multiply them by rating.\n",
        "    encoded_sequence_items_with_position_and_rating = layers.Multiply()(\n",
        "        [(encoded_sequence_items + encodded_positions), sequence_durations]\n",
        "    )\n",
        "\n",
        "    # Construct the transformer inputs.\n",
        "    for i in range(sequence_length - 1):\n",
        "        feature = encoded_sequence_items_with_position_and_rating[:, i, ...]\n",
        "        feature = keras.ops.expand_dims(feature, 1)\n",
        "        encoded_transformer_features.append(feature)\n",
        "    encoded_transformer_features.append(encoded_target_item)\n",
        "\n",
        "    encoded_transformer_features = layers.concatenate(\n",
        "        encoded_transformer_features, axis=1\n",
        "    )\n",
        "\n",
        "    return encoded_transformer_features, encoded_other_features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QGKKydwo5o0"
      },
      "source": [
        "# Create a BST model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "64vsuHOTo5o0"
      },
      "outputs": [],
      "source": [
        "include_session_id = False\n",
        "include_other_features = False\n",
        "include_item_features = True\n",
        "\n",
        "hidden_units = [256, 128]\n",
        "dropout_rate = 0.1\n",
        "num_heads = 3\n",
        "\n",
        "\n",
        "def create_model():\n",
        "    inputs = create_model_inputs()\n",
        "    transformer_features, other_features = encode_input_features(\n",
        "        inputs, include_session_id, include_other_features, include_item_features\n",
        "    )\n",
        "\n",
        "    # Create a multi-headed attention layer.\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=transformer_features.shape[2], dropout=dropout_rate\n",
        "    )(transformer_features, transformer_features)\n",
        "\n",
        "    # Transformer block.\n",
        "    attention_output = layers.Dropout(dropout_rate)(attention_output)\n",
        "    x1 = layers.Add()([transformer_features, attention_output])\n",
        "    x1 = layers.LayerNormalization()(x1)\n",
        "    x2 = layers.LeakyReLU()(x1)\n",
        "    x2 = layers.Dense(units=x2.shape[-1])(x2)\n",
        "    x2 = layers.Dropout(dropout_rate)(x2)\n",
        "    transformer_features = layers.Add()([x1, x2])\n",
        "    transformer_features = layers.LayerNormalization()(transformer_features)\n",
        "    features = layers.Flatten()(transformer_features)\n",
        "\n",
        "    # Included the other features.\n",
        "    if other_features is not None:\n",
        "        features = layers.concatenate(\n",
        "            [features, layers.Reshape([other_features.shape[-1]])(other_features)]\n",
        "        )\n",
        "\n",
        "    # Fully-connected layers.\n",
        "    for num_units in hidden_units:\n",
        "        features = layers.Dense(num_units)(features)\n",
        "        features = layers.BatchNormalization()(features)\n",
        "        features = layers.LeakyReLU()(features)\n",
        "        features = layers.Dropout(dropout_rate)(features)\n",
        "\n",
        "    outputs = layers.Dense(units=1)(features)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU9dj6Zio5o0"
      },
      "source": [
        "#Run training and evaluation experiment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import losses"
      ],
      "metadata": {
        "id": "EzvY1cADAKzd"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "D2APw2g-o5o0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e615c100-e872-426c-e86b-ca5ed2eb8dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py:22: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - loss: 1.1814e-05 - precision: 1.0000 - recall: 0.4070\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - loss: 1.1765e-05 - precision: 1.0000 - recall: 0.4060\n",
            "Epoch 3/5\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 1.1614e-05 - precision: 1.0000 - recall: 0.4091\n",
            "Epoch 4/5\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - loss: 1.1566e-05 - precision: 1.0000 - recall: 0.4080\n",
            "Epoch 5/5\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 1.2127e-05 - precision: 1.0000 - recall: 0.4049\n",
            "Test recall: 0.0\n"
          ]
        }
      ],
      "source": [
        "# Compile the model.\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adagrad(learning_rate=0.01),\n",
        "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "    metrics=[keras.metrics.Precision(name = 'precision'),\n",
        "             keras.metrics.Recall(name = 'recall')]\n",
        ")\n",
        "\n",
        "# Read the training data.\n",
        "train_dataset = get_dataset_from_csv(\"train_data.csv\", shuffle=True, batch_size=265)\n",
        "\n",
        "# Fit the model with the training data.\n",
        "model.fit(train_dataset, epochs=5)\n",
        "\n",
        "# Read the test data.\n",
        "test_dataset = get_dataset_from_csv(\"test_data.csv\", batch_size=265)\n",
        "\n",
        "# Evaluate the model on the test data.\n",
        "\n",
        "_, precision, recall = model.evaluate(test_dataset, verbose=0)\n",
        "print(f\"Test recall: {round(recall, 3)}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}