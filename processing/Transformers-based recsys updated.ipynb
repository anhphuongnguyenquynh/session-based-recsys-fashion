{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9GEtCX3BEXUq",
        "dMzw8c1OEjtO",
        "j9HtbRNzEhVQ",
        "KTXN2XITbcNA",
        "D-OzRPoKdgl2"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import libraries"
      ],
      "metadata": {
        "id": "9GEtCX3BEXUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset\n",
        "from torchtext.vocab import vocab\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNs2CQ2QE6sL",
        "outputId": "9854cdbe-2b9e-46a5-c84d-a17856fab9aa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Datasets"
      ],
      "metadata": {
        "id": "dMzw8c1OEjtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the data (session_id, item_id, date, Datetime, Timestamp)\n",
        "url01 = 'https://raw.githubusercontent.com/anhphuongnguyenquynh/session-based-recsys-fashion/main/dataset_filtered/train_session01_seq.csv'"
      ],
      "metadata": {
        "id": "aoZTIz0mcWeV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset01 = pd.read_csv(url01, index_col = 0, parse_dates=[\"date\"])\n",
        "dataset01 = dataset01.dropna()\n",
        "dataset01 = dataset01.reset_index()\n",
        "#fraction\n",
        "dataset = dataset01.sample(frac=1)\n",
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RvQUj53cX-5",
        "outputId": "a73a26b5-d509-4f4e-85a5-23f8d9c94a5a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(516944, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter item less than 5 interactions\n",
        "df_item_count = dataset[['item_id', 'session_id']].groupby('item_id').count().sort_values(by = 'session_id', ascending = False)\n",
        "df_item_count.columns = ['CountItemId']\n",
        "df_item_count_5 = df_item_count[df_item_count['CountItemId'] < 5]\n",
        "# remove item_id less than 5 interactions\n",
        "dataset = dataset[~dataset['item_id'].isin(list(df_item_count_5.index))]"
      ],
      "metadata": {
        "id": "7lKOib--cZcA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter session less than 2 iteractions\n",
        "df_session_count = dataset[['item_id', 'session_id']].groupby('session_id').count().sort_values(by = 'item_id', ascending = False)\n",
        "df_session_count.columns = ['items_in_session']\n",
        "df_session_count_2 = df_session_count[df_session_count['items_in_session'] < 2]\n",
        "# remove session_id less than 2 interactions\n",
        "dataset = dataset[~dataset['session_id'].isin(list(df_session_count_2.index))]"
      ],
      "metadata": {
        "id": "8LwOiReOcgwv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-u9xNRHchXo",
        "outputId": "70d0f507-f851-4faf-f2fd-fb2a61185edf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(253678, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unique item_id in dataset\n",
        "unique_item_id = dataset['item_id'].unique()"
      ],
      "metadata": {
        "id": "PZB7PxCccrtA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preventing ids to be written as integer or float data type\n",
        "dataset[\"session_id\"] = dataset[\"session_id\"].apply(lambda x: f\"session_{x}\")\n",
        "\n",
        "dataset[\"item_id\"] = dataset[\"item_id\"].apply(lambda x: f\"item_{x}\")"
      ],
      "metadata": {
        "id": "6KAXDY9gXk7k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Vocabulary"
      ],
      "metadata": {
        "id": "KTXN2XITbcNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#list of unique item ids\n",
        "item_ids = dataset.item_id.unique()\n",
        "\n",
        "#Counter is used to feed items to item_vocab\n",
        "item_counter = Counter(item_ids)\n",
        "\n",
        "#Genarting vocabulary\n",
        "item_vocab = vocab(item_counter, specials=['<unk>'])\n",
        "\n",
        "#For indexing input ids\n",
        "item_vocab_stoi = item_vocab.get_stoi()\n",
        "\n",
        "#Session_id vocab\n",
        "session_ids = dataset.session_id.unique()\n",
        "session_counter = Counter(session_ids)\n",
        "session_vocab = vocab(session_counter, specials=['<unk>'])\n",
        "session_vocab_stoi = session_vocab.get_stoi()"
      ],
      "metadata": {
        "id": "l8RxfgN7ba70"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Config"
      ],
      "metadata": {
        "id": "j9HtbRNzEhVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'num_items': len(item_vocab), #num_items + 1\n",
        "    'num_sessions': len(session_vocab), #13542 +1\n",
        "    'embedding_dim': 128,\n",
        "    'hidden_d': 128,\n",
        "    'trm_layers': 2,\n",
        "    'n_head': 2,\n",
        "    'dropout': 0.2,\n",
        "    'lr': 0.1,\n",
        "    'batch_size': 256,\n",
        "    'epochs': 5,\n",
        "    'label_smoothing': 0.1,\n",
        "    'topk': 20\n",
        "}\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MpVwDHHGCTn",
        "outputId": "6882140a-268b-4947-caac-7a4bea911243"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing Data"
      ],
      "metadata": {
        "id": "D-OzRPoKdgl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Group by session_id after sort_values by timestamp\n",
        "sessions_groups = dataset.sort_values(by=[\"timestamp\"]).groupby(\"session_id\")\n",
        "sessions_train = pd.DataFrame(data = {\n",
        "        \"session_id\": list(sessions_groups.groups.keys()),\n",
        "        \"month\" : list(sessions_groups.month.unique().explode()),\n",
        "        \"weekYear\" : list(sessions_groups.weekYear.unique().explode()),\n",
        "        \"season\" : list(sessions_groups.season.unique().explode()),\n",
        "        \"item_ids\": list(sessions_groups.item_id.apply(list)),\n",
        "        \"durations\": list(sessions_groups.duration.apply(list)),\n",
        "        \"timestamps\": list(sessions_groups.timestamp.apply(list)),\n",
        "    })"
      ],
      "metadata": {
        "id": "xCW2TGTukiid"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 6\n",
        "step = 2\n",
        "def create_sequences(values, sequence, step):\n",
        "  start_idx = 0\n",
        "  sec_list = []\n",
        "  #Handle case < sequence:\n",
        "  if len(values) < sequence:\n",
        "    values = values * 2\n",
        "  #Handle case >= sequence:\n",
        "  while True:\n",
        "    end_idx = start_idx + sequence\n",
        "    sec = values[start_idx:end_idx]\n",
        "    start_idx += step\n",
        "    if end_idx >= len(values):\n",
        "      sec = values[-sequence:]\n",
        "      sec_list.append(sec)\n",
        "      break\n",
        "    sec_list.append(sec)\n",
        "  return sec_list"
      ],
      "metadata": {
        "id": "6Kh59iQnklzG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sessions_train[\"item_ids\"] = sessions_train[\"item_ids\"].apply(\n",
        "    lambda values: create_sequences(\n",
        "        values,sequence_length, step))\n",
        "\n",
        "sessions_train[\"durations\"] = sessions_train[\"durations\"].apply(\n",
        "    lambda values: create_sequences(\n",
        "        values,sequence_length, step))\n",
        "\n",
        "sessions_train = sessions_train.drop(columns = [\"timestamps\"])\n",
        "\n",
        "sessions_train = sessions_train.explode(column=[\"item_ids\", \"durations\"]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "RxbZgGDakqQS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop weekYear and season\n",
        "#convert type column month to string\n",
        "sessions_train[\"month\"] = sessions_train[\"month\"].astype(str)\n",
        "sessions_train = sessions_train.drop(columns = [\"weekYear\", \"season\"])\n",
        "sessions_train.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "496q9iyHkw3o",
        "outputId": "735f7630-c61b-438f-ef55-c098118f79f8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          session_id month                                           item_ids  \\\n",
              "0  session_1000066.0  10.0  [item_22239.0, item_10408.0, item_15687.0, ite...   \n",
              "1  session_1000097.0  12.0  [item_21532.0, item_17992.0, item_17151.0, ite...   \n",
              "2  session_1000109.0   5.0  [item_23774.0, item_15429.0, item_23774.0, ite...   \n",
              "3  session_1000118.0   4.0  [item_23272.0, item_18125.0, item_18326.0, ite...   \n",
              "4  session_1000220.0   9.0  [item_12816.0, item_18743.0, item_12816.0, ite...   \n",
              "\n",
              "                                durations  \n",
              "0  [1.0, 1.0, 34975.0, 1.0, 1.0, 34975.0]  \n",
              "1          [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  \n",
              "2                    [1.0, 1.0, 1.0, 1.0]  \n",
              "3      [1.0, 1.0, 120.0, 1.0, 1.0, 120.0]  \n",
              "4                    [1.0, 1.0, 1.0, 1.0]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62d941bd-3876-45e0-98e1-39740e23607f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session_id</th>\n",
              "      <th>month</th>\n",
              "      <th>item_ids</th>\n",
              "      <th>durations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>session_1000066.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>[item_22239.0, item_10408.0, item_15687.0, ite...</td>\n",
              "      <td>[1.0, 1.0, 34975.0, 1.0, 1.0, 34975.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>session_1000097.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>[item_21532.0, item_17992.0, item_17151.0, ite...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>session_1000109.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[item_23774.0, item_15429.0, item_23774.0, ite...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>session_1000118.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>[item_23272.0, item_18125.0, item_18326.0, ite...</td>\n",
              "      <td>[1.0, 1.0, 120.0, 1.0, 1.0, 120.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>session_1000220.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>[item_12816.0, item_18743.0, item_12816.0, ite...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62d941bd-3876-45e0-98e1-39740e23607f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-62d941bd-3876-45e0-98e1-39740e23607f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-62d941bd-3876-45e0-98e1-39740e23607f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1b171b83-2c70-4c9e-9acf-51dd615db412\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b171b83-2c70-4c9e-9acf-51dd615db412')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1b171b83-2c70-4c9e-9acf-51dd615db412 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sessions_train"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train split data test"
      ],
      "metadata": {
        "id": "n0eqo3qwclxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train split data test\n",
        "random_selection = np.random.rand(len(sessions_train.index)) <= 0.85\n",
        "train_data = sessions_train[random_selection]\n",
        "test_data = sessions_train[~random_selection]"
      ],
      "metadata": {
        "id": "xPiZzPu3clNA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_raw = train_data[[\"session_id\", \"item_ids\"]].values\n",
        "test_data_raw = test_data[[\"session_id\", \"item_ids\"]].values"
      ],
      "metadata": {
        "id": "00KRdNg_WFPE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_raw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVIdYx3OZZiu",
        "outputId": "1f6609c9-96ff-4235-b445-e4b1a1baa3fa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['session_1000066.0',\n",
              "        list(['item_22239.0', 'item_10408.0', 'item_15687.0', 'item_22239.0', 'item_10408.0', 'item_15687.0'])],\n",
              "       ['session_1000097.0',\n",
              "        list(['item_21532.0', 'item_17992.0', 'item_17151.0', 'item_21532.0', 'item_17992.0', 'item_17151.0'])],\n",
              "       ['session_1000109.0',\n",
              "        list(['item_23774.0', 'item_15429.0', 'item_23774.0', 'item_15429.0'])],\n",
              "       ...,\n",
              "       ['session_999951.0',\n",
              "        list(['item_20087.0', 'item_23689.0', 'item_3499.0', 'item_20087.0', 'item_23689.0', 'item_3499.0'])],\n",
              "       ['session_999990.0',\n",
              "        list(['item_18764.0', 'item_26067.0', 'item_6548.0', 'item_13620.0', 'item_18764.0', 'item_26067.0'])],\n",
              "       ['session_999990.0',\n",
              "        list(['item_6548.0', 'item_13620.0', 'item_18764.0', 'item_26067.0', 'item_6548.0', 'item_13620.0'])]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Input for model and Data Loader"
      ],
      "metadata": {
        "id": "iaOSDgjEEqNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch Dataset for session interactions\n",
        "class ItemSeqDataset(Dataset):\n",
        "    # Initialize dataset\n",
        "    def __init__(self, data, item_vocab_stoi, session_vocab_stoi):\n",
        "        self.data = data\n",
        "\n",
        "        self.item_vocab_stoi = item_vocab_stoi\n",
        "        self.session_vocab_stoi = session_vocab_stoi\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    # Fetch data from the dataset\n",
        "    def __getitem__(self, idx):\n",
        "        session, item_sequence = self.data[idx]\n",
        "        # Directly index into the vocabularies\n",
        "        item_data = [self.item_vocab_stoi[item] for item in item_sequence]\n",
        "        session_data = self.session_vocab_stoi[session]\n",
        "        return torch.tensor(item_data), torch.tensor(session_data)\n",
        "\n",
        "\n",
        "# Collate function and padding\n",
        "def collate_batch(batch):\n",
        "    item_list = [item[0] for item in batch]\n",
        "    session_list = [item[1] for item in batch]\n",
        "    return pad_sequence(item_list, padding_value=item_vocab_stoi['<unk>'], batch_first=True), torch.stack(session_list)"
      ],
      "metadata": {
        "id": "v3DnrxWVk-ab"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = config['batch_size']\n",
        "# Create instances of your Dataset for each set\n",
        "train_dataset = ItemSeqDataset(train_data_raw, item_vocab_stoi, session_vocab_stoi)\n",
        "val_dataset = ItemSeqDataset(test_data_raw, item_vocab_stoi, session_vocab_stoi)\n",
        "# Create DataLoaders\n",
        "train_iter = DataLoader(train_dataset, batch_size=config['batch_size'],\n",
        "                        shuffle=True, collate_fn=collate_batch)\n",
        "val_iter = DataLoader(val_dataset, batch_size=config['batch_size'],\n",
        "                      shuffle=False, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "IJp8kDerlJAA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Architecture"
      ],
      "metadata": {
        "id": "E5Isq7itEsXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "\n",
        "        # `div_term` is used in the calculation of the sinusoidal values.\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # Initializing positional encoding matrix with zeros.\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "\n",
        "        # Calculating the positional encodings.\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "Maur16o_EztQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, num_items: int, num_session: int, d_model: int, nhead: int, d_hid: int,\n",
        "                 nlayers: int, dropout: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        # positional encoder\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "\n",
        "        # Multihead attention mechanism.\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "\n",
        "        # Embedding layers\n",
        "        self.item_embedding = nn.Embedding(num_items, d_model)\n",
        "        self.session_embedding = nn.Embedding(num_session, d_model)\n",
        "\n",
        "        # Defining the size of the input to the model.\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Linear layer to map the output toitem vocabulary.\n",
        "        self.linear = nn.Linear(2*d_model, num_items)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        # Initializing the weights of the embedding and linear layers.\n",
        "        initrange = 0.1\n",
        "        self.item_embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.session_embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.linear.bias.data.zero_()\n",
        "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src: Tensor, session: Tensor, src_mask: Tensor = None) -> Tensor:\n",
        "        # Embedding item ids and sessionid\n",
        "        #output item_embed (batch_size, sequence length, self.d_model)\n",
        "        #multiply with math.sqrt(self.d_model) -> scaling operation used in transformer models for stablize the training process\n",
        "        item_embed = self.item_embedding(src) * math.sqrt(self.d_model) #item_embed: [batch_size, 3, embed_dim = 128]\n",
        "        session_embed = self.session_embedding(session) * math.sqrt(self.d_model) #session_embed: [batch_size, 1, embed_dim = 128]\n",
        "\n",
        "        # positional encoding\n",
        "        item_embed = self.pos_encoder(item_embed) #item_embed pe: [batch_size, 3, embed_dim = 128]\n",
        "\n",
        "        # generating output with final layers\n",
        "        output = self.transformer_encoder(item_embed, src_mask) #output: [batch_size, 3, embed_dim = 128]\n",
        "\n",
        "        # Expand session_embed tensor along the sequence length dimension\n",
        "        session_embed = session_embed.expand(-1, output.size(1), -1) #session_embed: [batch_size, 3, embed_dim = 128]\n",
        "\n",
        "        # Concatenate session embeddings with transformer output\n",
        "        output = torch.cat((output, session_embed), dim=-1) #output: [batch_size, 3, embed_dim *2]\n",
        "\n",
        "        output = self.linear(output) #output linear: [batch_size, 3, num_items]\n",
        "        return output"
      ],
      "metadata": {
        "id": "LSPzeBlKkCcw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "1OJX1E0iEv18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerModel(num_items = config['num_items'],\n",
        "                         num_session = config['num_sessions'],\n",
        "                         d_model = config['embedding_dim'],\n",
        "                         nhead = config['n_head'],\n",
        "                         d_hid = config['hidden_d'],\n",
        "                         nlayers = config['trm_layers'],\n",
        "                         dropout = config['dropout'])\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=config['label_smoothing'])\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = config['lr'])\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CzjR4StaU5D",
        "outputId": "4c0e42fa-d02e-45c1-cf57-242f1dfdb60d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CShGENSa0C_",
        "outputId": "8e1c6a2b-7e07-4bf7-dc0e-a951caf6cfdb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerModel(\n",
            "  (pos_encoder): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "  )\n",
            "  (transformer_encoder): TransformerEncoder(\n",
            "    (layers): ModuleList(\n",
            "      (0-1): 2 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.2, inplace=False)\n",
            "        (dropout2): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (item_embedding): Embedding(14576, 128)\n",
            "  (session_embedding): Embedding(99352, 128)\n",
            "  (linear): Linear(in_features=256, out_features=14576, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train one epoch"
      ],
      "metadata": {
        "id": "iq3f-Z3kbL8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model: nn.Module, train_iter, epoch) -> None:\n",
        "    model.train()\n",
        "    total_loss = 0.\n",
        "    log_interval = 200\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, (item_data, session_data) in enumerate(train_iter):\n",
        "        # Load item sequence and session id\n",
        "        item_data, session_data = item_data.to(device), session_data.to(device) #item_data [batch_size, seq_length], session_data [batch_size]: list of session_id\n",
        "        session_data = session_data.reshape(-1, 1) #[[session1], [session2]...] reshape session_data [batch_size, 1]\n",
        "\n",
        "        # Split item sequence to inputs and targets\n",
        "        inputs, targets = item_data[:, :-1], item_data[:, 1:] #if max = 4: inputs[1,2,3]. Inputs [batch_size, 3]. targets [2,3,4]. targets [batch_size, 3]\n",
        "        targets_flat = targets.reshape(-1) #targets_flat [batch_size * seq_length]\n",
        "\n",
        "        # Predict items\n",
        "        output = model(inputs, session_data)\n",
        "        output_flat = output.reshape(-1, config['num_items']) # output_flat: [768, 8423] [batch_size *3, num_items]\n",
        "\n",
        "        # Backpropogation process\n",
        "        loss = criterion(output_flat, targets_flat)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        # Results\n",
        "        if i % log_interval == 0 and i > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            ppl = math.exp(cur_loss)\n",
        "            print(f'| epoch {epoch:3d} '\n",
        "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
        "            total_loss = 0\n",
        "            start_time = time.time()"
      ],
      "metadata": {
        "id": "dbYBAVL8bNrr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation"
      ],
      "metadata": {
        "id": "dDnxSIldExkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation metric"
      ],
      "metadata": {
        "id": "9yPShjpJ3DWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation metrics\n",
        "\n",
        "def recall_metric(indices, targets):\n",
        "  \"\"\"\n",
        "  Inputs: indices: [batch, top_k] indices of top_k items predicted\n",
        "          targets: [batch, (seq_len-1: ex: 3)] targets items in the sequences\n",
        "  Output: how many targets in indices\n",
        "\n",
        "  \"\"\"\n",
        "  recall = 0\n",
        "  check_recall_masked = torch.isin(indices, targets)\n",
        "  check_recall_count = check_recall_masked.double()\n",
        "  check_hits = torch.sum(check_recall_count) #return a torch.tensor([value.])\n",
        "  hits = check_hits.item() #return an integer\n",
        "\n",
        "  n = indices.numel() #return a total number of matrix targets\n",
        "\n",
        "  recall = hits/n\n",
        "  return recall"
      ],
      "metadata": {
        "id": "9IT5meMazyAj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_indices = torch.tensor([[2773, 136, 14, 56,77,88, 100, 89],\n",
        "                             [612, 20, 26, 22, 2026, 67, 12 ,14]])\n",
        "d_targets = torch.tensor([[2, 1], [20, 52]])"
      ],
      "metadata": {
        "id": "YB18i4md1f-y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_recall20 = recall_metric(indices = c_indices, targets = d_targets)\n",
        "print(check_recall20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SYIIt1H1FyR",
        "outputId": "2dc86440-700a-4915-cce8-3304222bd378"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation"
      ],
      "metadata": {
        "id": "l7UvSMsz3S4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
        "    model.eval()\n",
        "    total_loss = 0.\n",
        "\n",
        "    RECALL = []\n",
        "    with torch.no_grad():\n",
        "        for i, (item_data, session_data) in enumerate(eval_data):\n",
        "            # Load item sequence and session id\n",
        "            item_data, session_data = item_data.to(device), session_data.to(device)\n",
        "            session_data = session_data.reshape(-1, 1)\n",
        "            # Split item sequence to inputs and targets\n",
        "            inputs, targets = item_data[:, :-1], item_data[:, 1:]  #if max = 4: inputs[1,2,3]. Inputs [batch_size, 3]. targets [2,3,4]. targets [batch_size, 3]\n",
        "            targets_flat = targets.reshape(-1)\n",
        "            # Predict items\n",
        "            output = model(inputs, session_data)\n",
        "            output_flat = output.reshape(-1, config['num_items']) # output_flat: [768, 8423] [batch_size *3, num_items]\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(output_flat, targets_flat)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            #Get predictions\n",
        "            targets_flat = targets.reshape(-1) #targets_flat [batch_size*3]. Ex: [768]\n",
        "            # Reshape the output_flat to get top predictions\n",
        "            outputs = output_flat.reshape(output_flat.shape[0] // inputs.shape[1],\n",
        "                                          inputs.shape[1],\n",
        "                                          output_flat.shape[1])[: , -1, :] #outputs: [batch, num_items]\n",
        "            #values, indices = outputs.topk(k + inputs.shape[1], dim=-1) #dim = -1 sort\n",
        "            values, indices = outputs.topk(k = config['topk'], dim=-1)\n",
        "\n",
        "            #Evaluation\n",
        "            recall = recall_metric(indices = indices, targets = targets)\n",
        "            RECALL.append(recall)\n",
        "\n",
        "    recall_avg = sum(RECALL)/len(RECALL)\n",
        "    return total_loss / (len(eval_data) - 1), recall_avg"
      ],
      "metadata": {
        "id": "9tgDtGXIbk4x"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "epochs = config['epochs']\n",
        "\n",
        "with TemporaryDirectory() as tempdir:\n",
        "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        # Training\n",
        "        train(model, train_iter, epoch)\n",
        "\n",
        "        # Evaluation\n",
        "        val_loss, recall_avg = evaluate(model, val_iter)\n",
        "\n",
        "        # Compute the perplexity of the validation loss\n",
        "        val_ppl = math.exp(val_loss)\n",
        "        elapsed = time.time() - epoch_start_time\n",
        "\n",
        "        # Results\n",
        "        print('-' * 89)\n",
        "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}  | '\n",
        "            f'recall_avg {recall_avg}')\n",
        "        print('-' * 89)\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "        scheduler.step()\n",
        "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMjCAlZ-bzBM",
        "outputId": "7ff58b79-b257-458c-88a2-56530b4427ef"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 lr 0.10 | ms/batch 931.25 | loss  7.97 | ppl  2884.33\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 368.33s | valid loss  8.00 | valid ppl  2995.73  | recall_avg 0.45532275800945365\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 lr 0.10 | ms/batch 913.61 | loss  7.89 | ppl  2679.26\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 363.85s | valid loss  7.96 | valid ppl  2858.20  | recall_avg 0.47291910123424374\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 lr 0.09 | ms/batch 921.87 | loss  7.85 | ppl  2562.75\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 364.76s | valid loss  7.93 | valid ppl  2784.72  | recall_avg 0.46764476102941166\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 lr 0.09 | ms/batch 914.17 | loss  7.81 | ppl  2457.38\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 363.69s | valid loss  7.91 | valid ppl  2726.06  | recall_avg 0.4553144695378151\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 lr 0.08 | ms/batch 910.41 | loss  7.77 | ppl  2379.65\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 362.46s | valid loss  7.90 | valid ppl  2693.62  | recall_avg 0.44827714679621855\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hide check test"
      ],
      "metadata": {
        "id": "C71f5I7XPYLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# item id decoder\n",
        "item_vocab_itos = item_vocab.get_itos()\n",
        "\n",
        "# A placeholders to store results of recommendations\n",
        "transformer_reco_results = list()\n",
        "popular_reco_results = list()\n",
        "\n",
        "# Get top 20 items\n",
        "k = 20\n",
        "\n",
        "for i, (item_data, session_data) in enumerate(val_iter):\n",
        "    # Feed the input and get the outputs\n",
        "    item_data, session_data = item_data.to(device), session_data.to(device)\n",
        "    session_data = session_data.reshape(-1, 1)\n",
        "    #Split item sequence to inputs and targets\n",
        "    inputs, targets = item_data[:, :-1], item_data[:, 1:]  #if max = 4: inputs[1,2,3]. Inputs [batch_size, 3]. targets [2,3,4]. targets [batch_size, 3]\n",
        "    #Predict items\n",
        "    output = model(inputs, session_data)\n",
        "    print(output.shape, '---check output_shape')\n",
        "    output_flat = output.reshape(-1, config['num_items']) # output_flat: [768, 8423] [batch_size *3, num_items]\n",
        "    targets_flat = targets.reshape(-1) #targets_flat [batch_size*3]. Ex: [768]\n",
        "\n",
        "    # Reshape the output_flat to get top predictions\n",
        "    outputs = output_flat.reshape(output_flat.shape[0] // inputs.shape[1],\n",
        "                                  inputs.shape[1],\n",
        "                                  output_flat.shape[1])[: , -1, :] #outputs: [batch, num_items]\n",
        "\n",
        "    # k + len(inputs) = 13 items obtained\n",
        "    # In order to prevent to recommend already watched items\n",
        "    #values, indices = outputs.topk(k + inputs.shape[1], dim=-1) #dim = -1 sort\n",
        "    values, indices = outputs.topk(k, dim=-1)\n",
        "    #Do not elimiate the already viewed item. Select top 20 and check whether targets in values -> Recall +=1\n",
        "    #check last items của targets với list indices -> +=1 recall\n",
        "\n",
        "    print(values, '---check values')\n",
        "    print(values.shape, 'values.shape')\n",
        "    print(indices, '----check indices')\n",
        "    print(indices.shape, 'indices.shape')\n",
        "    print(targets, '---check targets')\n",
        "    print(targets.shape, 'targets.shape')\n",
        "    #Evaluation\n",
        "    recall = recall_metric(indices, targets)\n",
        "    print(recall, '---check recall')\n",
        "\n"
      ],
      "metadata": {
        "id": "EvVoBAnWI4ej",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "91a7b1bf-29fe-4e93-e14a-e13052d7a9ad"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[ 6.6801,  3.7687,  3.3213,  ...,  2.0875,  2.0703,  2.0642],\n",
            "        [ 5.8806,  3.1083,  3.0574,  ...,  2.0170,  2.0141,  1.9947],\n",
            "        [ 5.5980,  3.1642,  2.8103,  ...,  2.1719,  2.1708,  2.1620],\n",
            "        ...,\n",
            "        [13.1127,  4.3965,  3.6370,  ...,  2.1403,  2.1287,  2.1280],\n",
            "        [12.9421,  4.0065,  2.8360,  ...,  2.2437,  2.2158,  2.2063],\n",
            "        [12.9985,  4.1481,  3.6392,  ...,  2.2716,  2.2634,  2.1905]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,    42,  ...,  3147,  8361, 14382],\n",
            "        [    0,   331,    42,  ...,  1214,  4378,  4981],\n",
            "        [    0,    42,   331,  ..., 12264,  5760,  4378],\n",
            "        ...,\n",
            "        [    0,   331,    42,  ...,  8763,  5315,  3996],\n",
            "        [    0,    42,   331,  ...,  4471,  7412, 11584],\n",
            "        [    0,   331,    42,  ...,  1868,   164,  6991]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 9602,  7306, 13387,  9602,  7306],\n",
            "        [ 6491, 13810, 10691, 12182,  6491],\n",
            "        [10691, 12182,  6491, 13810, 10691],\n",
            "        ...,\n",
            "        [ 1643,  3450,  1643,     0,     0],\n",
            "        [ 6715, 13344,  6715,     0,     0],\n",
            "        [  461,  9251,   461,     0,     0]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.284765625 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[13.1491,  3.7443,  3.0769,  ...,  2.1771,  2.1746,  2.1723],\n",
            "        [ 5.4358,  3.4607,  3.2439,  ...,  2.1420,  2.1374,  2.1024],\n",
            "        [13.1121,  3.3114,  3.0840,  ...,  2.2613,  2.2532,  2.2442],\n",
            "        ...,\n",
            "        [13.1039,  3.8002,  2.5871,  ...,  2.1129,  2.0947,  2.0423],\n",
            "        [13.2498,  4.1396,  3.0747,  ...,  2.2194,  2.2127,  2.2123],\n",
            "        [13.1484,  3.8109,  2.8332,  ...,  2.2724,  2.2663,  2.2470]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,    42,  ...,   260,  1942,  9731],\n",
            "        [    0,    42, 14514,  ..., 14519,   464,  3878],\n",
            "        [    0,   331,    42,  ...,  1196, 10181,  3996],\n",
            "        ...,\n",
            "        [    0,   331,  5759,  ...,   167,  3888,   118],\n",
            "        [    0,   331,    42,  ...,  9322,  3816,  6178],\n",
            "        [    0,    42,   331,  ...,   871,  2180,  1628]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 2733,  7875,  2733,     0,     0],\n",
            "        [ 8865,  4623, 12507,  8865,  4623],\n",
            "        [ 4221,  2720,  4221,     0,     0],\n",
            "        ...,\n",
            "        [  316,  3792,   316,     0,     0],\n",
            "        [   11,   627,    11,     0,     0],\n",
            "        [ 2496,  4676,  2496,     0,     0]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.322265625 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[12.9381,  3.3621,  3.3484,  ...,  2.1091,  2.0997,  2.0983],\n",
            "        [13.2159,  4.0928,  3.5317,  ...,  2.2899,  2.2874,  2.2722],\n",
            "        [ 5.7933,  3.0499,  2.8789,  ...,  2.2751,  2.2747,  2.2583],\n",
            "        ...,\n",
            "        [ 7.6521,  3.9701,  3.4331,  ...,  2.1517,  2.1512,  2.1352],\n",
            "        [13.3177,  3.7549,  3.3242,  ...,  2.1921,  2.1911,  2.1902],\n",
            "        [ 6.9541,  3.9113,  3.8448,  ...,  2.3265,  2.3151,  2.2830]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,    42,  ...,  7553,  3693,   246],\n",
            "        [    0,   331,    42,  ...,  1214,  4000,   705],\n",
            "        [    0,    42,  4849,  ...,  4405,  6574,  2541],\n",
            "        ...,\n",
            "        [    0,   331,    42,  ..., 14534,   548,  4569],\n",
            "        [    0,   331,    42,  ...,  3261,  5767,  4124],\n",
            "        [    0,   331,    42,  ...,  1214,  3189, 10362]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 1786,  1786,  1786,     0,     0],\n",
            "        [ 1941,  1283,  1941,     0,     0],\n",
            "        [ 5091,  3020,  9430,  5091,  3020],\n",
            "        ...,\n",
            "        [ 3263, 12108, 10629,  8539,  3263],\n",
            "        [ 7544,  5325,  7544,     0,     0],\n",
            "        [10835,   529, 11288, 10835,   529]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.2482421875 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[13.0900,  4.2274,  3.1860,  ...,  2.1698,  2.1577,  2.1534],\n",
            "        [13.0041,  3.3340,  3.0310,  ...,  2.2782,  2.2649,  2.2536],\n",
            "        [ 6.7632,  3.3123,  2.9897,  ...,  2.1370,  2.1302,  2.1291],\n",
            "        ...,\n",
            "        [13.0625,  4.0630,  3.4964,  ...,  2.1618,  2.1528,  2.1454],\n",
            "        [13.0307,  4.0527,  3.3591,  ...,  2.1422,  2.1272,  2.1250],\n",
            "        [ 6.6193,  3.6101,  3.2092,  ...,  2.1559,  2.1256,  2.1080]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,   167,  ...,  1888, 10475,  2676],\n",
            "        [    0,    42,   331,  ...,   118,   370,  2781],\n",
            "        [    0,    42,   331,  ...,  9413,  1868,  9666],\n",
            "        ...,\n",
            "        [    0,   331,    42,  ...,   871,  1868,  9050],\n",
            "        [    0,   331,    42,  ...,  1628,  9431,  5272],\n",
            "        [    0,   167,    42,  ..., 13808,  3578,  8697]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 2470,  1864,  2470,     0,     0],\n",
            "        [ 1164,  3586,  1164,     0,     0],\n",
            "        [ 1595,  3134,  2732, 11934,  1595],\n",
            "        ...,\n",
            "        [ 2568,  9051,  2568,     0,     0],\n",
            "        [ 5833,  2570,  5833,     0,     0],\n",
            "        [ 6117,  5673,  7068,  6117,  6117]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.3330078125 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[ 6.3628,  3.7177,  3.5446,  ...,  2.1094,  2.0783,  2.0675],\n",
            "        [13.0830,  3.8522,  3.7924,  ...,  2.1436,  2.1247,  2.0637],\n",
            "        [12.9262,  3.1360,  3.0584,  ...,  2.2045,  2.1966,  2.1922],\n",
            "        ...,\n",
            "        [ 6.3573,  3.8125,  3.2896,  ...,  2.2324,  2.2145,  2.2039],\n",
            "        [13.0786,  3.5658,  3.3537,  ...,  2.1964,  2.1945,  2.1785],\n",
            "        [ 6.9166,  4.5066,  3.8685,  ...,  2.2006,  2.1910,  2.1688]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,    42,  ...,  1012,  3587,  9884],\n",
            "        [    0,   331,    42,  ...,  2054,  2523,  6673],\n",
            "        [    0,   331,    42,  ...,  4152,    43,  3264],\n",
            "        ...,\n",
            "        [    0,    42,   167,  ...,  1933,   922, 12558],\n",
            "        [    0,    42,   331,  ...,  5454,  6377,  3096],\n",
            "        [    0,    42,   331,  ...,  5486,   627,  6991]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 2169,  2169,  5679,  2169,  2169],\n",
            "        [ 8514,  4351,  8514,     0,     0],\n",
            "        [ 7687,  3542,  7687,     0,     0],\n",
            "        ...,\n",
            "        [12773,  5806,  8779, 12773,  5806],\n",
            "        [ 3205, 13511,  3205,     0,     0],\n",
            "        [ 6766,  7259, 13295,  6766,  7259]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.36484375 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[13.1254,  3.9350,  3.8863,  ...,  2.2252,  2.2226,  2.2158],\n",
            "        [ 6.2273,  3.7328,  3.1839,  ...,  1.9741,  1.9689,  1.9661],\n",
            "        [ 6.4721,  4.4227,  4.1549,  ...,  2.0875,  2.0414,  2.0164],\n",
            "        ...,\n",
            "        [ 7.0688,  3.4529,  3.1163,  ...,  2.2385,  2.2292,  2.2073],\n",
            "        [12.9914,  3.8469,  3.2082,  ...,  2.1162,  2.1135,  2.1115],\n",
            "        [13.2100,  4.0511,  3.4771,  ...,  2.2190,  2.2060,  2.1997]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,    42,  ...,  1196,  6901,  9276],\n",
            "        [    0,   331,    42,  ...,  7028,   976,  2012],\n",
            "        [    0,   331,    42,  ..., 12432,  2343, 13007],\n",
            "        ...,\n",
            "        [    0,   331,   271,  ...,   701, 12305,  4569],\n",
            "        [    0,   331,    42,  ..., 10662,  3367,  1864],\n",
            "        [    0,   331,   167,  ...,  3996,   946,  6945]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 5639,   182,  5639,     0,     0],\n",
            "        [ 4442,  5556,  5239,  4442,  5556],\n",
            "        [ 1968,   644,   341,  7389,  1968],\n",
            "        ...,\n",
            "        [10227,  8915,  6040, 10227,  8915],\n",
            "        [ 9937,  2964,  9937,     0,     0],\n",
            "        [ 7256, 12161,  7256,     0,     0]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.38515625 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[13.1192,  3.6593,  3.1013,  ...,  2.0994,  2.0980,  2.0819],\n",
            "        [13.1493,  3.7503,  3.2868,  ...,  2.2211,  2.2132,  2.2077],\n",
            "        [13.1691,  4.2033,  2.8980,  ...,  2.0948,  2.0805,  2.0670],\n",
            "        ...,\n",
            "        [13.2788,  3.5172,  3.0773,  ...,  2.2938,  2.2838,  2.2506],\n",
            "        [13.1460,  3.9855,  3.4217,  ...,  2.2357,  2.2263,  2.2258],\n",
            "        [12.8960,  3.9327,  3.7944,  ...,  2.1609,  2.1447,  2.1305]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,    42,  ..., 11746,  6056,  8308],\n",
            "        [    0,   331,    42,  ...,   620,  7243,  6377],\n",
            "        [    0,   331,  1214,  ...,  5355, 12367,  6481],\n",
            "        ...,\n",
            "        [    0,   331,   167,  ..., 11551,  1919,   375],\n",
            "        [    0,   331,    42,  ..., 13061,  6178,  2088],\n",
            "        [    0,    42,   331,  ...,   233, 14550,  4561]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[  659, 11575,   659,     0,     0],\n",
            "        [ 2489, 11644,  2489,     0,     0],\n",
            "        [  580,  5561,   580,     0,     0],\n",
            "        ...,\n",
            "        [ 1840,  1471,  1840,     0,     0],\n",
            "        [ 7127,  4237,  7127,     0,     0],\n",
            "        [ 6421,  7575,  6421,     0,     0]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.3009765625 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[13.1414,  3.4265,  2.9526,  ...,  2.2844,  2.2705,  2.2701],\n",
            "        [13.1380,  4.2083,  3.5196,  ...,  2.2790,  2.2477,  2.2386],\n",
            "        [13.1168,  3.7042,  3.6575,  ...,  2.2272,  2.2241,  2.2092],\n",
            "        ...,\n",
            "        [ 6.0599,  3.4038,  2.8540,  ...,  2.1980,  2.1528,  2.1477],\n",
            "        [ 6.4720,  3.3985,  2.8676,  ...,  2.1291,  2.1251,  2.1108],\n",
            "        [ 4.9600,  3.1749,  3.1724,  ...,  2.0818,  2.0760,  2.0705]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,   167,  ...,  4000,  3733,  7016],\n",
            "        [    0,   331,    42,  ...,  8386,  5706,  4210],\n",
            "        [    0,    42,   331,  ...,  4907,  7542,  1214],\n",
            "        ...,\n",
            "        [    0,    42,  3965,  ...,  5470,  2806, 11990],\n",
            "        [    0,    42,   331,  ...,  3130, 13773,   496],\n",
            "        [    0,    42,   167,  ...,  8031,  1740,  3192]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 1027, 12223,  1027,     0,     0],\n",
            "        [    8,   258,     8,     0,     0],\n",
            "        [13720,  1919, 13720,     0,     0],\n",
            "        ...,\n",
            "        [  702, 13835,  2484,  4467,  3628],\n",
            "        [ 3628,   702, 13835,  2484,  4467],\n",
            "        [   36,  7093,  5628,    36,  7093]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.3330078125 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[13.1402,  3.9210,  3.6125,  ...,  2.1592,  2.1568,  2.1544],\n",
            "        [13.0675,  3.5127,  3.2985,  ...,  2.1909,  2.1874,  2.1864],\n",
            "        [13.2111,  3.9858,  3.2241,  ...,  2.1652,  2.1383,  2.1323],\n",
            "        ...,\n",
            "        [ 6.2435,  3.2094,  3.1770,  ...,  2.0357,  2.0340,  2.0286],\n",
            "        [12.8963,  4.0428,  3.3062,  ...,  2.2594,  2.2419,  2.2253],\n",
            "        [12.9705,  3.3781,  3.1145,  ...,  2.0820,  2.0698,  2.0688]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,    42,  ...,  1345, 10173, 12410],\n",
            "        [    0,    42,   331,  ...,    98, 11393,  3888],\n",
            "        [    0,   331,    42,  ...,  1420,  2489, 11987],\n",
            "        ...,\n",
            "        [    0,   167,   331,  ...,   602,  8787,  8113],\n",
            "        [    0,    42,   756,  ...,   587, 10007,   567],\n",
            "        [    0,   331,  1868,  ...,  9533,   375,  3888]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 6505, 10942,  6505,     0,     0],\n",
            "        [ 4106,   979,  4106,     0,     0],\n",
            "        [ 9427,  5541,  9427,     0,     0],\n",
            "        ...,\n",
            "        [ 2998,  6857,  6502,  2998,  6857],\n",
            "        [ 2444,  2784,  2444,     0,     0],\n",
            "        [ 1523,  2600,  1523,     0,     0]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.33671875 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[13.0405,  4.1648,  3.7651,  ...,  2.2261,  2.2230,  2.1989],\n",
            "        [ 5.8767,  3.5958,  3.5424,  ...,  2.1789,  2.1458,  2.1236],\n",
            "        [13.1419,  4.1869,  3.7409,  ...,  2.1852,  2.1820,  2.1585],\n",
            "        ...,\n",
            "        [ 7.3856,  3.8365,  3.6676,  ...,  2.1806,  2.1663,  2.1446],\n",
            "        [12.9520,  3.6216,  3.2298,  ...,  2.0616,  2.0608,  2.0567],\n",
            "        [ 6.9956,  3.9422,  3.8078,  ...,  2.1659,  2.1093,  2.1088]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,    42,  ...,  1232, 10602,   946],\n",
            "        [    0,   167,   331,  ...,  3297,  9884,   233],\n",
            "        [    0,    42,   331,  ...,  2412,   266,  1986],\n",
            "        ...,\n",
            "        [    0,   331,    42,  ..., 13992,  3025,  6574],\n",
            "        [    0,    42,   331,  ...,   709, 11874,  1559],\n",
            "        [    0,    42,   331,  ...,  1864,  1139,  3914]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[  894,  4350,   894,     0,     0],\n",
            "        [14097,   954,   954, 14097, 14097],\n",
            "        [ 9348,  4057,  9348,     0,     0],\n",
            "        ...,\n",
            "        [ 9410, 11272,   148,  9410, 11272],\n",
            "        [ 3043,   298,  3043,     0,     0],\n",
            "        [ 9155, 13777, 13294,  8165,  9973]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.35703125 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[ 6.5511,  3.1667,  2.7778,  ...,  2.2625,  2.2426,  2.2411],\n",
            "        [13.2276,  3.9174,  3.2372,  ...,  2.1853,  2.1792,  2.1693],\n",
            "        [13.0143,  3.4678,  2.9947,  ...,  2.2503,  2.2412,  2.1994],\n",
            "        ...,\n",
            "        [ 6.2962,  4.1695,  2.8526,  ...,  2.2689,  2.2630,  2.2565],\n",
            "        [12.9667,  3.7358,  3.2318,  ...,  2.2747,  2.2524,  2.2329],\n",
            "        [12.9800,  3.9892,  3.6415,  ...,  2.2497,  2.2429,  2.2388]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,   370,  ...,  6247,  2957,  1998],\n",
            "        [    0,   331,    42,  ...,  1482,  1345,  2582],\n",
            "        [    0,   331,  9541,  ...,   370,  4181,   114],\n",
            "        ...,\n",
            "        [    0,   331,    42,  ...,  1906,   584,  5027],\n",
            "        [    0,    42,   331,  ...,   756,  9089, 14008],\n",
            "        [    0,    42,   331,  ...,   463,  6480,  1628]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 8106,  5531,   876,  8106,  5531],\n",
            "        [ 6017,  6187,  6017,     0,     0],\n",
            "        [ 4324,  4081,  4324,     0,     0],\n",
            "        ...,\n",
            "        [ 3075,  2955,  5629,  5363,  3075],\n",
            "        [ 5736,  8959,  5736,     0,     0],\n",
            "        [ 1256, 10077,  1256,     0,     0]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.2755859375 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[ 6.2084,  3.3453,  3.1846,  ...,  2.1443,  2.1342,  2.1328],\n",
            "        [13.0828,  3.9692,  3.9577,  ...,  2.2526,  2.2455,  2.2262],\n",
            "        [12.9557,  4.0233,  3.2857,  ...,  2.2701,  2.2562,  2.2354],\n",
            "        ...,\n",
            "        [13.1221,  3.9341,  3.7335,  ...,  2.2619,  2.2619,  2.2503],\n",
            "        [12.9274,  3.6317,  3.4285,  ...,  2.2320,  2.2231,  2.2228],\n",
            "        [ 6.8797,  3.3601,  3.2528,  ...,  2.1687,  2.1549,  2.0883]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,    42,   331,  ...,  4988,  1200,   701],\n",
            "        [    0,    42,   331,  ...,  1357,  9545,   783],\n",
            "        [    0,    42,   331,  ...,  3700,  7604,  3924],\n",
            "        ...,\n",
            "        [    0,    42,   331,  ..., 10662,  5622,   578],\n",
            "        [    0,    42,   331,  ...,   233,  4710, 10956],\n",
            "        [    0,   331,   167,  ...,  1377,  4405,  9397]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 1601,  1601,   669,  7622, 11252],\n",
            "        [ 2031,  2275,  2031,     0,     0],\n",
            "        [ 5626,  8514,  5626,     0,     0],\n",
            "        ...,\n",
            "        [ 5554, 10082,  5554,     0,     0],\n",
            "        [12128,  8680, 12128,     0,     0],\n",
            "        [ 1199, 12020,  9704,  4946, 12345]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.2896484375 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[13.0002,  4.2304,  3.7106,  ...,  2.2349,  2.1814,  2.1652],\n",
            "        [ 7.2906,  4.4424,  3.9237,  ...,  2.1046,  2.0882,  2.0630],\n",
            "        [13.3178,  3.5004,  3.3876,  ...,  2.1889,  2.1783,  2.1724],\n",
            "        ...,\n",
            "        [13.1500,  3.1262,  3.1215,  ...,  2.3320,  2.3001,  2.2744],\n",
            "        [13.0312,  2.6714,  2.5911,  ...,  2.2153,  2.1755,  2.1441],\n",
            "        [ 6.5807,  3.9037,  3.5705,  ...,  2.0535,  2.0387,  2.0339]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,    42,   331,  ...,  4710,  1168,   548],\n",
            "        [    0,   331,    42,  ...,  3257,   496, 11753],\n",
            "        [    0,    42,   331,  ...,   995,  1345,  1868],\n",
            "        ...,\n",
            "        [    0,   331,    42,  ...,  2412,  1864,  6056],\n",
            "        [    0,   167,   922,  ...,   682,  1214, 12227],\n",
            "        [    0,   331,    42,  ...,  6310,  1740,  7547]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 2913,  2874,  2913,     0,     0],\n",
            "        [10920, 10190,  2029, 10920, 10190],\n",
            "        [ 2269,  2228,  2269,     0,     0],\n",
            "        ...,\n",
            "        [ 7475,   207,  7475,     0,     0],\n",
            "        [  123,  3450,   123,     0,     0],\n",
            "        [ 2252,  2144,  2252,  2097,   602]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.346484375 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[ 5.7077,  3.3487,  2.9534,  ...,  2.1687,  2.1577,  2.1399],\n",
            "        [13.0939,  3.8845,  3.0281,  ...,  2.1207,  2.1035,  2.0922],\n",
            "        [ 5.2019,  3.0599,  2.9314,  ...,  2.2067,  2.1972,  2.1868],\n",
            "        ...,\n",
            "        [ 6.5423,  2.9194,  2.7518,  ...,  2.1915,  2.1767,  2.1689],\n",
            "        [13.0037,  3.3767,  2.8967,  ...,  2.1813,  2.1737,  2.1713],\n",
            "        [ 7.3729,  4.0342,  3.3145,  ...,  2.1748,  2.1533,  2.1421]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[   0,  331,   42,  ...,   66, 1868, 3945],\n",
            "        [   0,  331,   42,  ...,   98, 7481, 9059],\n",
            "        [   0,   42, 1919,  ...,  552, 1763, 5084],\n",
            "        ...,\n",
            "        [   0,  167,  271,  ..., 4914,  381,  701],\n",
            "        [   0,   42,  331,  ...,  946,  822, 2518],\n",
            "        [   0,  331,   42,  ..., 3542,   43, 6991]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[7979, 2758, 5655, 7979, 2758],\n",
            "        [1919, 4568, 1919,    0,    0],\n",
            "        [4668,  679, 1089, 4668,  679],\n",
            "        ...,\n",
            "        [6020,  422,  351, 6020,  422],\n",
            "        [ 464, 4513,  464,    0,    0],\n",
            "        [ 665, 4718, 2436,  665, 4718]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.3365234375 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[ 5.9088,  4.0801,  3.5729,  ...,  2.2222,  2.2161,  2.2048],\n",
            "        [13.0732,  4.5478,  3.7212,  ...,  2.1445,  2.1359,  2.1280],\n",
            "        [12.9461,  3.7578,  3.7231,  ...,  2.1812,  2.1792,  2.1722],\n",
            "        ...,\n",
            "        [13.0593,  3.4899,  3.3858,  ...,  2.0734,  2.0687,  2.0680],\n",
            "        [12.8794,  4.1531,  3.7132,  ...,  2.1780,  2.1709,  2.1580],\n",
            "        [12.6434,  4.0811,  3.5493,  ...,  2.1741,  2.1429,  2.1394]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,    42,   331,  ..., 13115,  1868,   577],\n",
            "        [    0,   331,    42,  ...,   375, 10662,  6887],\n",
            "        [    0,   331,    42,  ...,  2343,  3264,  5851],\n",
            "        ...,\n",
            "        [    0,   167,   331,  ..., 10956,    59,   233],\n",
            "        [    0,    42,   331,  ...,  9755, 13426, 14162],\n",
            "        [    0,   331,    42,  ...,   756,   627,  3281]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[  331,  4096,  3865,  1782,   331],\n",
            "        [  772,  3130,   772,     0,     0],\n",
            "        [ 4182,  2312,  4182,     0,     0],\n",
            "        ...,\n",
            "        [ 5872,  3450,  5872,     0,     0],\n",
            "        [12319, 13386, 12319,     0,     0],\n",
            "        [ 3012,  5782,  3012,     0,     0]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.3068359375 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[13.1471,  3.7218,  2.9697,  ...,  2.0738,  2.0645,  2.0588],\n",
            "        [13.1270,  3.6752,  3.3886,  ...,  2.2053,  2.1821,  2.1607],\n",
            "        [13.2621,  3.8572,  3.4047,  ...,  2.2636,  2.2566,  2.2410],\n",
            "        ...,\n",
            "        [13.2732,  3.2896,  3.2536,  ...,  2.1905,  2.1823,  2.1498],\n",
            "        [13.2272,  4.2265,  3.4791,  ...,  2.0698,  2.0667,  2.0621],\n",
            "        [12.8205,  3.2222,  2.7136,  ...,  2.2080,  2.1835,  2.1823]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,    42,  ..., 11551,  9541,   370],\n",
            "        [    0,   331,    42,  ...,  7604,  1868,  6502],\n",
            "        [    0,    42,   331,  ..., 11918, 10379,  7125],\n",
            "        ...,\n",
            "        [    0,    42,   331,  ...,  1888,   578,  4003],\n",
            "        [    0,   331,    42,  ...,   285,  3914,  1214],\n",
            "        [    0,    42,   331,  ...,  5355,  4166,  8477]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 271, 6522,  271,    0,    0],\n",
            "        [ 104, 2769,  104,    0,    0],\n",
            "        [7577, 1850, 7577,    0,    0],\n",
            "        ...,\n",
            "        [2044, 4734, 2044,    0,    0],\n",
            "        [3526, 8143, 3526,    0,    0],\n",
            "        [4534, 4815, 4534,    0,    0]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.3037109375 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[12.9203,  3.7594,  3.6802,  ...,  2.2611,  2.2479,  2.2138],\n",
            "        [12.9485,  3.5483,  2.7738,  ...,  2.1873,  2.1638,  2.1461],\n",
            "        [ 5.1661,  3.1860,  2.8979,  ...,  2.2211,  2.2158,  2.2154],\n",
            "        ...,\n",
            "        [13.0674,  3.7416,  3.2439,  ...,  2.2658,  2.2566,  2.2498],\n",
            "        [13.1117,  3.5392,  3.1981,  ...,  2.1163,  2.1129,  2.1122],\n",
            "        [13.0387,  3.8038,  3.3415,  ...,  2.2215,  2.2005,  2.1962]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,    42,  ...,  2180, 11961,  1599],\n",
            "        [    0,   331,    42,  ...,  8926,   375,  2104],\n",
            "        [    0,    42,   331,  ...,  6012, 10788,  1200],\n",
            "        ...,\n",
            "        [    0,    42,   331,  ...,  3096,   314, 11568],\n",
            "        [    0,    42,   331,  ...,  4741,  6991,  1214],\n",
            "        [    0,    42,   331,  ...,  2412,    83,  3130]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[2874, 1590, 2874,    0,    0],\n",
            "        [9701, 9195, 9701,    0,    0],\n",
            "        [2134, 2055,  440, 8110, 2134],\n",
            "        ...,\n",
            "        [8080,  914, 8080,    0,    0],\n",
            "        [3873,  505, 3873,    0,    0],\n",
            "        [1496,  578, 1496,    0,    0]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.3181640625 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[12.7945,  3.6690,  3.4152,  ...,  2.1934,  2.1921,  2.1529],\n",
            "        [13.0594,  4.1975,  3.9905,  ...,  2.1140,  2.1055,  2.1045],\n",
            "        [ 7.0272,  4.1244,  3.9833,  ...,  2.0678,  2.0589,  2.0465],\n",
            "        ...,\n",
            "        [13.1388,  3.6805,  3.5655,  ...,  2.1234,  2.1168,  2.1062],\n",
            "        [12.9195,  3.2600,  2.9289,  ...,  2.2294,  2.2147,  2.2020],\n",
            "        [ 6.4070,  3.7649,  3.5464,  ...,  2.0954,  2.0942,  2.0766]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,    42,   331,  ...,   375,   964,  4000],\n",
            "        [    0,   331,    42,  ..., 13633, 13061,  4464],\n",
            "        [    0,   331,    42,  ...,  6284,  8845,   263],\n",
            "        ...,\n",
            "        [    0,    42,   331,  ...,   590,  2637,  1959],\n",
            "        [    0,   331,    42,  ...,   121,  8845,   118],\n",
            "        [    0,   331,    42,  ...,  2012,  2842,  3578]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 8403,  8403,  8403,     0,     0],\n",
            "        [ 9791, 10147,  9791,     0,     0],\n",
            "        [ 4103,  2166,   810,  4103,  2166],\n",
            "        ...,\n",
            "        [ 7811, 12596,  7811,     0,     0],\n",
            "        [ 1472,   930,  1472,     0,     0],\n",
            "        [ 1697,  3527,  6040,  4401,  8674]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.37734375 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[13.1216,  4.5121,  3.6583,  ...,  2.1632,  2.1487,  2.1314],\n",
            "        [13.0011,  3.7432,  3.1408,  ...,  2.2396,  2.2395,  2.2222],\n",
            "        [13.0213,  3.7620,  3.7031,  ...,  2.2267,  2.2042,  2.1887],\n",
            "        ...,\n",
            "        [ 5.7212,  2.7038,  2.5616,  ...,  2.1374,  2.1284,  2.1175],\n",
            "        [13.0405,  3.4065,  2.6974,  ...,  2.1790,  2.1732,  2.1715],\n",
            "        [ 6.9590,  3.4110,  2.8395,  ...,  2.1635,  2.1526,  2.1345]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,    42,  ...,   370,     4,  4000],\n",
            "        [    0,   331,   114,  ...,  1345,  4300,  8800],\n",
            "        [    0,   331,    42,  ...,  2180, 10766, 13100],\n",
            "        ...,\n",
            "        [    0,   331,   818,  ...,   703,  4617,    59],\n",
            "        [    0,    42,   331,  ...,   308,  1168,   238],\n",
            "        [    0,    42,   331,  ...,  3397,   964,  3996]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 8737,  6596,  8737,     0,     0],\n",
            "        [ 3711, 12589,  3711,     0,     0],\n",
            "        [ 7407,  3245,  7407,     0,     0],\n",
            "        ...,\n",
            "        [ 8964,  7538,  9843,  3365,  8448],\n",
            "        [ 4429, 11746,  4429,     0,     0],\n",
            "        [  107,  6503,  8682,   107,  6503]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.283203125 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[12.9735,  3.2479,  2.9271,  ...,  2.1895,  2.1793,  2.1478],\n",
            "        [13.1077,  3.8620,  3.8005,  ...,  2.1800,  2.1747,  2.1638],\n",
            "        [ 6.3315,  3.6600,  3.6447,  ...,  2.1381,  2.1240,  2.1020],\n",
            "        ...,\n",
            "        [ 5.0360,  3.4462,  2.9964,  ...,  2.1657,  2.1389,  2.1351],\n",
            "        [13.0430,  3.6575,  3.6205,  ...,  2.1797,  2.1639,  2.1570],\n",
            "        [ 6.6182,  3.0186,  2.9513,  ...,  2.1455,  2.1236,  2.1157]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,    42,  ...,  1942,  2387,  1888],\n",
            "        [    0,    42,   331,  ...,  2423, 11393,  1345],\n",
            "        [    0,   331,    42,  ...,  5939,  7343,  1842],\n",
            "        ...,\n",
            "        [    0,   331,   167,  ..., 11468,   496, 11783],\n",
            "        [    0,   167,   331,  ...,  1864,  9184,  3621],\n",
            "        [    0,   331,   167,  ...,   361,  1864,  5832]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[  853,  5263,   853,     0,     0],\n",
            "        [ 4878,  2206,  4878,     0,     0],\n",
            "        [ 1268,  7073, 13108,  2805,  1259],\n",
            "        ...,\n",
            "        [ 4066,   271,  2282,  1208,  4066],\n",
            "        [ 8633,  9846,  8633,     0,     0],\n",
            "        [ 2603,  1457,  2836,  4875,   333]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.3046875 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[13.1202,  3.8988,  3.7589,  ...,  2.1309,  2.1217,  2.1147],\n",
            "        [ 5.7553,  2.9809,  2.7534,  ...,  2.3125,  2.2872,  2.2781],\n",
            "        [13.2294,  3.4322,  2.8035,  ...,  2.0856,  2.0851,  2.0785],\n",
            "        ...,\n",
            "        [13.0700,  3.3677,  3.1520,  ...,  2.1870,  2.1758,  2.1281],\n",
            "        [13.1564,  3.4410,  3.1180,  ...,  2.2256,  2.2062,  2.1781],\n",
            "        [ 5.2841,  2.5979,  2.5674,  ...,  2.2177,  2.2137,  2.2046]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,    42,   331,  ...,  7160,  6066,  7137],\n",
            "        [    0,   331,  1906,  ...,  4731,  1757,  8927],\n",
            "        [    0,   331,    42,  ...,  9887,  1723,  4000],\n",
            "        ...,\n",
            "        [    0,   331,    42,  ...,  4136,  3996,  9891],\n",
            "        [    0,   331,   167,  ..., 10060,  1757,   627],\n",
            "        [    0,   331,   645,  ...,    11, 12344,    42]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 5443,  6723,  5443,     0,     0],\n",
            "        [ 7524, 10767,  4054,  7524, 10767],\n",
            "        [  379,  6882,   379,     0,     0],\n",
            "        ...,\n",
            "        [ 9010, 12084,  9010,     0,     0],\n",
            "        [ 6208,  6113,  6208,     0,     0],\n",
            "        [ 1850,  3981,   566,  9914,  1586]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.2501953125 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[ 6.9227,  3.3612,  3.1494,  ...,  2.1160,  2.1107,  2.1031],\n",
            "        [ 6.6168,  3.1747,  3.0544,  ...,  2.1992,  2.1767,  2.1628],\n",
            "        [ 6.2094,  4.3534,  3.8512,  ...,  2.0859,  2.0636,  2.0613],\n",
            "        ...,\n",
            "        [13.0634,  3.8337,  3.4469,  ...,  2.1775,  2.1765,  2.1504],\n",
            "        [ 6.3614,  3.2969,  2.8326,  ...,  2.1539,  2.1501,  2.1114],\n",
            "        [ 6.3823,  3.1786,  2.7162,  ...,  2.0724,  2.0637,  2.0636]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,  1919,  ...,  7311,    11,  5619],\n",
            "        [    0,   167,    42,  ..., 14296,  5272,  9568],\n",
            "        [    0,    42,   331,  ..., 12149,  6293,  1920],\n",
            "        ...,\n",
            "        [    0,    42,   331,  ...,   233,  9306,  5270],\n",
            "        [    0,   331,   271,  ...,  5949,  3004,    55],\n",
            "        [    0,    42,   331,  ...,  4834,  5149,  2180]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[  566,  9914,  1586,  1850,  3981],\n",
            "        [11337,  6621,  1105, 11337,  6621],\n",
            "        [ 3746,   149,  4756,   839,  4188],\n",
            "        ...,\n",
            "        [ 8549,  3542,  8549,     0,     0],\n",
            "        [ 4615,  4735,  8169,  4615,  4735],\n",
            "        [ 3852,  3830,  4141,  3830,  2905]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.3533203125 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[12.9858,  4.1607,  3.1451,  ...,  2.1651,  2.0988,  2.0916],\n",
            "        [ 6.0530,  3.5717,  2.6210,  ...,  2.1282,  2.1262,  2.1137],\n",
            "        [ 4.6053,  3.4424,  2.7082,  ...,  2.1600,  2.1580,  2.1571],\n",
            "        ...,\n",
            "        [13.1527,  3.4792,  2.9609,  ...,  2.2617,  2.2444,  2.2247],\n",
            "        [ 6.0085,  3.8523,  3.4471,  ...,  2.3060,  2.2890,  2.2803],\n",
            "        [ 5.2222,  3.7895,  3.2063,  ...,  2.1453,  2.1410,  2.1331]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,    42,  ...,   167,  3934,  3761],\n",
            "        [    0,   331,    42,  ..., 14322,  1984,   687],\n",
            "        [    0,   331,  5142,  ...,   942,  9119,  3034],\n",
            "        ...,\n",
            "        [    0,   331,    42,  ...,  1919,   548,  6635],\n",
            "        [    0,   331,    42,  ...,   964,  2518,  1214],\n",
            "        [    0,   331,    42,  ...,  2280,  5760,  4988]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 4214, 10277,  4214,     0,     0],\n",
            "        [ 2633,  2633,  1669,   765,  2633],\n",
            "        [ 1669,   765,  2633,  2633,  1669],\n",
            "        ...,\n",
            "        [  758,  8483,   758,     0,     0],\n",
            "        [ 6634, 10780,  1467,  5738,   351],\n",
            "        [ 1467,  5738,   351,  6634, 10780]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.3681640625 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[12.7470,  4.0026,  3.8521,  ...,  2.1649,  2.1578,  2.1563],\n",
            "        [13.0089,  3.7977,  2.9285,  ...,  2.3203,  2.2603,  2.2588],\n",
            "        [ 6.7408,  3.7764,  3.1341,  ...,  2.0735,  2.0642,  2.0359],\n",
            "        ...,\n",
            "        [13.1309,  3.9394,  2.8188,  ...,  2.2185,  2.1953,  2.1904],\n",
            "        [12.9078,  4.3671,  3.2992,  ...,  2.2808,  2.2667,  2.2073],\n",
            "        [ 6.5827,  3.9580,  3.0480,  ...,  2.1939,  2.1879,  2.1755]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,    42,   331,  ...,  4076,  8897,   783],\n",
            "        [    0,   331,  9541,  ...,   578,  1768,  1345],\n",
            "        [    0,    42,  1919,  ...,  3945, 10197,  2180],\n",
            "        ...,\n",
            "        [    0,   331,    42,  ...,    43,  5272,  3693],\n",
            "        [    0,   331,    42,  ...,  6279,  9822,  2518],\n",
            "        [    0,   331,    42,  ...,  9535,  3646,  8016]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[  370,   234,   370,     0,     0],\n",
            "        [ 3144,  3144,  3144,     0,     0],\n",
            "        [11184,  7217,  6019, 11184,  7217],\n",
            "        ...,\n",
            "        [ 2297,  4161,  2297,     0,     0],\n",
            "        [ 4207,  1775,  4207,     0,     0],\n",
            "        [10670,  5657,   310, 10670,  5657]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.40859375 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[ 5.7037,  3.4779,  3.1652,  ...,  2.0960,  2.0898,  2.0745],\n",
            "        [ 6.4717,  3.9616,  3.7502,  ...,  2.0985,  2.0923,  2.0919],\n",
            "        [13.1764,  3.1144,  2.8407,  ...,  2.2571,  2.2511,  2.2409],\n",
            "        ...,\n",
            "        [13.1671,  4.1744,  3.4230,  ...,  2.2615,  2.2496,  2.2258],\n",
            "        [13.2366,  3.7133,  3.6525,  ...,  2.2301,  2.2118,  2.2058],\n",
            "        [13.0189,  4.2549,  3.5941,  ...,  2.1580,  2.1272,  2.1098]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,    42,   331,  ...,  3500,   552,  1919],\n",
            "        [    0,   331,    42,  ...,  2945,   980,  3565],\n",
            "        [    0,   331, 11551,  ...,  2781,  4003, 11032],\n",
            "        ...,\n",
            "        [    0,   331,    42,  ...,  3627,  1919,   118],\n",
            "        [    0,   331,    42,  ..., 13355,  4753,  9541],\n",
            "        [    0,    42,   331,  ...,  1559,   271,   995]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 8145,  2139,  7366,  1165,  8145],\n",
            "        [ 4819,  3403,    76,  4819,  3403],\n",
            "        [ 6701,  6013,  6701,     0,     0],\n",
            "        ...,\n",
            "        [ 2905,  6045,  2905,     0,     0],\n",
            "        [ 3751, 10861,  3751,     0,     0],\n",
            "        [ 3528,  3600,  3528,     0,     0]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.2900390625 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[13.0758,  3.6042,  3.2485,  ...,  2.0915,  2.0544,  2.0369],\n",
            "        [ 5.9933,  4.1583,  3.2361,  ...,  2.1457,  2.1294,  2.1190],\n",
            "        [ 5.2985,  4.2255,  2.9298,  ...,  2.1865,  2.1543,  2.1390],\n",
            "        ...,\n",
            "        [ 6.0793,  3.2719,  3.0026,  ...,  2.1289,  2.1103,  2.0953],\n",
            "        [ 6.1216,  3.1069,  2.9804,  ...,  2.0767,  2.0748,  2.0655],\n",
            "        [13.0306,  3.8110,  3.7273,  ...,  2.2679,  2.2366,  2.2361]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,    42,   331,  ...,  1345,  2104, 13678],\n",
            "        [    0,    42,   331,  ...,  4711,   801,   703],\n",
            "        [    0,    42,   331,  ..., 12344,  5028,   199],\n",
            "        ...,\n",
            "        [    0,   331,   756,  ...,  3228,  1919,   194],\n",
            "        [    0,   167,    42,  ..., 11707,  7656,   298],\n",
            "        [    0,   331,    42,  ...,  4764,   756,  4565]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 4725, 11185,  4725,     0,     0],\n",
            "        [ 5435,  9723, 13256, 11009,   603],\n",
            "        [  603,  5435,  9723, 13256, 11009],\n",
            "        ...,\n",
            "        [ 2180,  3043,  5603,  2180,  3043],\n",
            "        [ 9364,  2740,  2012,  9364,  2740],\n",
            "        [ 2107,  1144,  2107,     0,     0]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.3611328125 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[ 6.5509,  3.5605,  3.4960,  ...,  2.1713,  2.1589,  2.1411],\n",
            "        [13.0580,  4.2196,  3.4867,  ...,  2.3744,  2.3355,  2.2841],\n",
            "        [ 6.5508,  3.8875,  3.8024,  ...,  2.0632,  2.0598,  2.0385],\n",
            "        ...,\n",
            "        [ 6.9904,  3.6747,  3.4890,  ...,  2.1147,  2.1129,  2.0905],\n",
            "        [ 6.1574,  3.5522,  3.2984,  ...,  2.1189,  2.1082,  2.0722],\n",
            "        [ 6.8597,  3.0410,  2.6753,  ...,  2.1496,  2.1244,  2.1165]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,    42,  ...,  1919,   980,   167],\n",
            "        [    0,   331,    42,  ...,    43,   475,     4],\n",
            "        [    0,   331,    42,  ...,   298,  3617, 11030],\n",
            "        ...,\n",
            "        [    0,   331,    42,  ...,  1906,   140,  3996],\n",
            "        [    0,   331,    42,  ..., 14468,  6854,  1214],\n",
            "        [    0,   331,    42,  ...,   567,  1919,   333]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[ 1500,  1108,   390,  1500,  1108],\n",
            "        [  365, 11513,   365,     0,     0],\n",
            "        [ 9965, 11653,  2760, 11381, 12143],\n",
            "        ...,\n",
            "        [ 6551,  5720,  6556,  5696,  3887],\n",
            "        [ 6556,  5696,  3887,  6551,  5720],\n",
            "        [ 1900,  3815,  3028,  1900,  3815]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.4369140625 ---check recall\n",
            "torch.Size([256, 5, 14576]) ---check output_shape\n",
            "tensor([[12.9720,  3.4785,  3.4458,  ...,  2.0579,  2.0575,  2.0406],\n",
            "        [ 5.6862,  3.5296,  3.0792,  ...,  2.0280,  2.0267,  2.0138],\n",
            "        [13.2073,  4.1777,  3.7647,  ...,  2.2415,  2.1800,  2.1531],\n",
            "        ...,\n",
            "        [13.1147,  3.9536,  3.5525,  ...,  2.1064,  2.0947,  2.0839],\n",
            "        [ 6.4580,  4.0355,  3.7366,  ...,  2.2259,  2.1922,  2.1730],\n",
            "        [12.9536,  3.7809,  3.3688,  ...,  2.1990,  2.1981,  2.1814]],\n",
            "       grad_fn=<TopkBackward0>) ---check values\n",
            "torch.Size([256, 20]) values.shape\n",
            "tensor([[    0,   331,    42,  ...,   333,  5206,  1196],\n",
            "        [    0,   331,    42,  ...,  6247, 11175,  1870],\n",
            "        [    0,   331,    42,  ..., 12042,  4414,  3982],\n",
            "        ...,\n",
            "        [    0,   331,    42,  ...,  6419,  2104,  1888],\n",
            "        [    0,   331,    42,  ..., 12478, 13627, 13764],\n",
            "        [    0,    42,   331,  ...,  9573,  1864,  6481]]) ----check indices\n",
            "torch.Size([256, 20]) indices.shape\n",
            "tensor([[  121, 10058,   121,     0,     0],\n",
            "        [ 1624,  4741, 11919,  1624,  4741],\n",
            "        [ 5623,   233,  5623,     0,     0],\n",
            "        ...,\n",
            "        [   99,  3348,    99,     0,     0],\n",
            "        [ 5607,  4811,  4947,  5607,  4811],\n",
            "        [ 6528,  7454,  6528,     0,     0]]) ---check targets\n",
            "torch.Size([256, 5]) targets.shape\n",
            "0.2796875 ---check recall\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-1deefd613241>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#if max = 4: inputs[1,2,3]. Inputs [batch_size, 3]. targets [2,3,4]. targets [batch_size, 3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#Predict items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'---check output_shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moutput_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_items'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# output_flat: [768, 8423] [batch_size *3, num_items]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-ab9a26d19ce1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, session, src_mask)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#output: [batch_size, 3, embed_dim *2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#output linear: [batch_size, 3, num_items]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##check test"
      ],
      "metadata": {
        "id": "aYmn0wFH3XyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def get_recall(indices, targets):\n",
        "    \"\"\"\n",
        "    Tính toán chỉ số recall cho một tập hợp predictions và targets\n",
        "    Args:\n",
        "        indices (Bxk): torch.LongTensor. top-k indices được dự báo từ mô hình model.\n",
        "        targets (B): torch.LongTensor. actual target indices.\n",
        "    Returns:\n",
        "        recall (float): the recall score\n",
        "    \"\"\"\n",
        "    # copy targets k lần để trở thành kích thước Bxk\n",
        "    targets = targets.view(-1, 1).expand_as(indices)\n",
        "    # so sánh targets với indices để tìm ra vị trí mà khách hàng sẽ hit.\n",
        "    hits = (targets == indices).to(device)\n",
        "    hits = hits.double()\n",
        "    if targets.size(0) == 0:\n",
        "        return 0\n",
        "    # Đếm số hit\n",
        "    n_hits = torch.sum(hits)\n",
        "    recall = n_hits / targets.size(0)\n",
        "    return recall"
      ],
      "metadata": {
        "id": "Ci3ezLlGfUu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_targets = torch.tensor([[ 111, 2773,  136],\n",
        "        [226, 6162, 2026]])"
      ],
      "metadata": {
        "id": "78aZIYXkfub-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_indices = torch.tensor([[2773, 136, 14, 56,77,88, 100, 89],\n",
        "                             [612, 20, 26, 22, 2026, 67, 12 ,14]])"
      ],
      "metadata": {
        "id": "iJRDT2Pck4-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_targets.shape"
      ],
      "metadata": {
        "id": "nfYFg3OQgpKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_target_last_item = test_targets[:,-1:]"
      ],
      "metadata": {
        "id": "9boT2zFxf2aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expand_target = test_target_last_item.expand_as(test_indices)\n",
        "print(expand_target)"
      ],
      "metadata": {
        "id": "sXCW6MFZl2Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hits = (expand_target == test_indices).to(device)\n",
        "print(hits)"
      ],
      "metadata": {
        "id": "s1O7lzFNmJq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hits = hits.double()\n",
        "print(hits)"
      ],
      "metadata": {
        "id": "Ao_00fEvmO2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_hits = torch.sum(hits)\n",
        "print(n_hits)"
      ],
      "metadata": {
        "id": "rotjvWYkmXrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = test_indices.numel()\n",
        "print(n)"
      ],
      "metadata": {
        "id": "2NPUjlXQma5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(n_hits/n)"
      ],
      "metadata": {
        "id": "wrfDFJQnnwUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor([1, 234, 54, 6543, 55, 776])\n",
        "b = torch.tensor([234, 54])\n",
        "\n",
        "c_indices = torch.tensor([[2773, 136, 14, 56,77,88, 100, 89],\n",
        "                             [612, 20, 26, 22, 2026, 67, 12 ,14]])\n",
        "d_targets = torch.tensor([[2, 1], [20, 52]])\n",
        "\n",
        "c_masked = torch.isin(c_indices, d_targets)\n",
        "print(c_masked)\n",
        "\n",
        "a_masked1 = sum(a == i for i in b)\n",
        "print(a_masked1)\n",
        "\n",
        "a_masked = sum(a == i for i in b).bool()\n",
        "\n",
        "print(a_masked)\n"
      ],
      "metadata": {
        "id": "honzrGvithVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(c_masked.double())"
      ],
      "metadata": {
        "id": "6OnFIBt5xjcA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}