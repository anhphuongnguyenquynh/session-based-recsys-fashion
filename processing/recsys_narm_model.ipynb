{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time"
      ],
      "metadata": {
        "id": "bA4rRpVa73pV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Datasets"
      ],
      "metadata": {
        "id": "mANFd1cm7skT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/anhphuongnguyenquynh/session-based-recsys-fashion/main/dataset/item_features.csv'\n",
        "item_features = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "lBusXiMZ_ShB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/anhphuongnguyenquynh/session-based-recsys-fashion/main/dressipi_recsys2022_datasets.zip'\n",
        "!wget $url\n",
        "!unzip dressipi_recsys2022_datasets.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GetVEmvZ_S6i",
        "outputId": "ed5714d0-acd2-4a1e-8c2c-9662593a9e81"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-25 16:57:10--  https://raw.githubusercontent.com/anhphuongnguyenquynh/session-based-recsys-fashion/main/dressipi_recsys2022_datasets.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 79384785 (76M) [application/zip]\n",
            "Saving to: ‘dressipi_recsys2022_datasets.zip’\n",
            "\n",
            "dressipi_recsys2022 100%[===================>]  75.71M   215MB/s    in 0.4s    \n",
            "\n",
            "2024-04-25 16:57:10 (215 MB/s) - ‘dressipi_recsys2022_datasets.zip’ saved [79384785/79384785]\n",
            "\n",
            "Archive:  dressipi_recsys2022_datasets.zip\n",
            "   creating: dressipi_recsys2022_dataset/\n",
            "  inflating: dressipi_recsys2022_dataset/README.txt  \n",
            "  inflating: dressipi_recsys2022_dataset/candidate_items.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/item_features.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/test_final_purchases.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/test_final_sessions.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/test_full_purchases.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/test_full_sessions.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/test_leaderboard_purchases.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/test_leaderboard_sessions.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/train_purchases.csv  \n",
            "  inflating: dressipi_recsys2022_dataset/train_sessions.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X_EKjExWIB8",
        "outputId": "5d2c14f1-7274-4576-be97-6716e8079ca5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dressipi_recsys2022_dataset  dressipi_recsys2022_datasets.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sessions = pd.read_csv('dressipi_recsys2022_dataset/train_sessions.csv')\n",
        "train_purchases = pd.read_csv('dressipi_recsys2022_dataset/train_purchases.csv')\n",
        "item_features = pd.read_csv('dressipi_recsys2022_dataset/item_features.csv')\n",
        "candidate_items = pd.read_csv('dressipi_recsys2022_dataset/candidate_items.csv')\n",
        "test_full_sessions = pd.read_csv('dressipi_recsys2022_dataset/test_full_sessions.csv')\n",
        "test_full_purchases = pd.read_csv('dressipi_recsys2022_dataset/test_full_purchases.csv')"
      ],
      "metadata": {
        "id": "nIRGUpF9NusY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sessions.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xKH3mZsxWR8T",
        "outputId": "96d4e16b-8cf5-471f-b8f3-3066877af6e1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   session_id  item_id                     date\n",
              "0           3     9655  2020-12-18 21:25:00.373\n",
              "1           3     9655  2020-12-18 21:19:48.093\n",
              "2          13    15654  2020-03-13 19:35:27.136\n",
              "3          18    18316  2020-08-26 19:18:30.833\n",
              "4          18     2507  2020-08-26 19:16:31.211"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c536a68d-893d-49c2-a566-3e4212384cb9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>9655</td>\n",
              "      <td>2020-12-18 21:25:00.373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>9655</td>\n",
              "      <td>2020-12-18 21:19:48.093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13</td>\n",
              "      <td>15654</td>\n",
              "      <td>2020-03-13 19:35:27.136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18</td>\n",
              "      <td>18316</td>\n",
              "      <td>2020-08-26 19:18:30.833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>2507</td>\n",
              "      <td>2020-08-26 19:16:31.211</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c536a68d-893d-49c2-a566-3e4212384cb9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c536a68d-893d-49c2-a566-3e4212384cb9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c536a68d-893d-49c2-a566-3e4212384cb9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert date to timestamp\n",
        "train_sessions['date'] = pd.to_datetime(train_sessions['date'], format='ISO8601')\n",
        "train_sessions['timestamp'] = train_sessions['date'].map(datetime.timestamp)\n",
        "train_sessions.head(5)"
      ],
      "metadata": {
        "id": "fdeTgbCqoxT3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "eaf48021-0ea5-40fc-d532-e6fe297140dd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   session_id  item_id                    date     timestamp\n",
              "0           3     9655 2020-12-18 21:25:00.373  1.608327e+09\n",
              "1           3     9655 2020-12-18 21:19:48.093  1.608326e+09\n",
              "2          13    15654 2020-03-13 19:35:27.136  1.584128e+09\n",
              "3          18    18316 2020-08-26 19:18:30.833  1.598470e+09\n",
              "4          18     2507 2020-08-26 19:16:31.211  1.598469e+09"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e0745b4-6de9-4a61-a235-dbfc6d6936aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>date</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>9655</td>\n",
              "      <td>2020-12-18 21:25:00.373</td>\n",
              "      <td>1.608327e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>9655</td>\n",
              "      <td>2020-12-18 21:19:48.093</td>\n",
              "      <td>1.608326e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13</td>\n",
              "      <td>15654</td>\n",
              "      <td>2020-03-13 19:35:27.136</td>\n",
              "      <td>1.584128e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18</td>\n",
              "      <td>18316</td>\n",
              "      <td>2020-08-26 19:18:30.833</td>\n",
              "      <td>1.598470e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>2507</td>\n",
              "      <td>2020-08-26 19:16:31.211</td>\n",
              "      <td>1.598469e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e0745b4-6de9-4a61-a235-dbfc6d6936aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e0745b4-6de9-4a61-a235-dbfc6d6936aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e0745b4-6de9-4a61-a235-dbfc6d6936aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert date to timestamp\n",
        "test_full_sessions['date'] = pd.to_datetime(test_full_sessions['date'], format='ISO8601')\n",
        "test_full_sessions['timestamp'] = test_full_sessions['date'].map(datetime.timestamp)\n",
        "test_full_sessions.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PtpOlpHckSJy",
        "outputId": "d21fb266-f183-43e4-e3f9-fe3d512d28bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   session_id  item_id                    date     timestamp\n",
              "0          26    19185 2021-06-16 09:53:54.158  1.623837e+09\n",
              "1          61    27088 2021-06-01 08:12:39.664  1.622535e+09\n",
              "2          61     5581 2021-06-01 08:12:40.534  1.622535e+09\n",
              "3          96    11693 2021-06-19 17:48:05.227  1.624125e+09\n",
              "4          96    18298 2021-06-19 17:49:08.589  1.624125e+09"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-361e8beb-e8e9-4e72-98dd-10eab3f60f67\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>date</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26</td>\n",
              "      <td>19185</td>\n",
              "      <td>2021-06-16 09:53:54.158</td>\n",
              "      <td>1.623837e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>61</td>\n",
              "      <td>27088</td>\n",
              "      <td>2021-06-01 08:12:39.664</td>\n",
              "      <td>1.622535e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>61</td>\n",
              "      <td>5581</td>\n",
              "      <td>2021-06-01 08:12:40.534</td>\n",
              "      <td>1.622535e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96</td>\n",
              "      <td>11693</td>\n",
              "      <td>2021-06-19 17:48:05.227</td>\n",
              "      <td>1.624125e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>96</td>\n",
              "      <td>18298</td>\n",
              "      <td>2021-06-19 17:49:08.589</td>\n",
              "      <td>1.624125e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-361e8beb-e8e9-4e72-98dd-10eab3f60f67')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-361e8beb-e8e9-4e72-98dd-10eab3f60f67 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-361e8beb-e8e9-4e72-98dd-10eab3f60f67');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train/Test split\n",
        "The dataset is splited already:\n",
        "- train_sessions for training\n",
        "- test_full_sessions for the last month for tesing"
      ],
      "metadata": {
        "id": "sEG2LwNgWLAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = train_sessions\n",
        "test = test_full_sessions"
      ],
      "metadata": {
        "id": "Kzg5FPFWoX6w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.shape)\n",
        "print(test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gVlV3T_WMp4",
        "outputId": "68020328-1a08-457c-de17-6ab930f6c5a0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4743820, 4)\n",
            "(595992, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rg1M16KfnNVd",
        "outputId": "a7a85819-7cf6-4a5e-fb6e-74009a9df714"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   session_id  item_id                    date     timestamp\n",
              "0           3     9655 2020-12-18 21:25:00.373  1.608327e+09\n",
              "1           3     9655 2020-12-18 21:19:48.093  1.608326e+09\n",
              "2          13    15654 2020-03-13 19:35:27.136  1.584128e+09\n",
              "3          18    18316 2020-08-26 19:18:30.833  1.598470e+09\n",
              "4          18     2507 2020-08-26 19:16:31.211  1.598469e+09"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d23f7c7-f923-4c9a-87bd-7d5bc26d2101\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>date</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>9655</td>\n",
              "      <td>2020-12-18 21:25:00.373</td>\n",
              "      <td>1.608327e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>9655</td>\n",
              "      <td>2020-12-18 21:19:48.093</td>\n",
              "      <td>1.608326e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13</td>\n",
              "      <td>15654</td>\n",
              "      <td>2020-03-13 19:35:27.136</td>\n",
              "      <td>1.584128e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18</td>\n",
              "      <td>18316</td>\n",
              "      <td>2020-08-26 19:18:30.833</td>\n",
              "      <td>1.598470e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>2507</td>\n",
              "      <td>2020-08-26 19:16:31.211</td>\n",
              "      <td>1.598469e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d23f7c7-f923-4c9a-87bd-7d5bc26d2101')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8d23f7c7-f923-4c9a-87bd-7d5bc26d2101 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8d23f7c7-f923-4c9a-87bd-7d5bc26d2101');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['session_id']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfWdGF9LoMnY",
        "outputId": "4ebd1da7-5ced-4d6f-93bd-59e44972301b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                3\n",
              "1                3\n",
              "2               13\n",
              "3               18\n",
              "4               18\n",
              "            ...   \n",
              "4743815    4440001\n",
              "4743816    4440001\n",
              "4743817    4440001\n",
              "4743818    4440001\n",
              "4743819    4440001\n",
              "Name: session_id, Length: 4743820, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Lấy ngẫu nhiên 1/4 số lượng các session cho huấn luyện\n",
        "# list các sessionIds\n",
        "import numpy as np\n",
        "sessIds = list(dataset['session_id'].unique())\n",
        "# Lấy ngẫu nhiên 1/4 số lượng các session\n",
        "n_filter = int(len(sessIds)/4)\n",
        "np.random.shuffle(sessIds)\n",
        "sessIdsFilter = sessIds[:n_filter]\n",
        "# Lựa chọn các 1/4 session làm dataset train (dữ liệu này bao gồm cả train và validation)\n",
        "# Set index là sessionId để filter nhanh hơn\n",
        "dataset.set_index('session_id', inplace=True)\n",
        "dataset_filter = dataset[dataset.index.isin(sessIdsFilter)]\n",
        "dataset_filter = dataset_filter.reset_index()\n",
        "print(dataset_filter.shape)"
      ],
      "metadata": {
        "id": "X9bDPh-ffJMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35b18fb-efc4-4525-e84b-99133e8e43e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1180645, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lấy ra dictionary có dạng {SessionId:{ItemId1:Timestamp1, ItemId2:Timestamp2, ...}}\n",
        "train_sess = dataset_filter[['session_id', 'item_id', 'timestamp']].groupby('session_id').apply(lambda x: dict(zip(x['item_id'], x['timestamp'])))\n",
        "test_sess = test[['session_id', 'item_id', 'timestamp']].groupby('session_id').apply(lambda x: dict(zip(x['item_id'], x['timestamp'])))"
      ],
      "metadata": {
        "id": "qy_IpxDWfLeT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5P_kj2Bphtf",
        "outputId": "13a0090b-ab96-4283-f323-448dfd2748e7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "session_id\n",
              "48             {8398: 1586971062.594, 26404: 1586971719.697}\n",
              "49                                   {21358: 1588336430.844}\n",
              "154                                  {21152: 1587713021.545}\n",
              "184                                  {14383: 1617500534.691}\n",
              "195        {4086: 1609848055.97, 16626: 1609805948.996, 1...\n",
              "                                 ...                        \n",
              "4439891                              {16607: 1608153366.575}\n",
              "4439894    {10186: 1617194216.962, 1103: 1617193787.576, ...\n",
              "4439900    {5515: 1598559911.646, 19475: 1598558432.32, 5...\n",
              "4439936                              {23764: 1618584742.939}\n",
              "4439968    {26650: 1591897126.2, 22773: 1591896462.481, 1...\n",
              "Length: 250000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing data"
      ],
      "metadata": {
        "id": "oR34_AEOYVDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sessDict = {214834865: '1396808691.295000', 214706441: '1396808691.426000', 214820225: '1396808691.422000'}\n",
        "\n",
        "def _preprocess_sess_dict(sessDict):\n",
        "    sessDictTime = dict([(v, k) for (k, v) in sessDict.items()])\n",
        "    sessSort = sorted(sessDictTime.items(), reverse = False)\n",
        "    times = [item[0] for item in sessSort]\n",
        "    itemIds = [item[1] for item in sessSort]\n",
        "    inp_seq = []\n",
        "    labels = []\n",
        "    inp_time = []\n",
        "\n",
        "    for i in range(len(sessSort)):\n",
        "        if i >= 1:\n",
        "            inp_seq += [itemIds[:i]]\n",
        "            labels += [itemIds[i]]\n",
        "            inp_time += [times[i]]\n",
        "    return inp_seq, inp_time, labels, itemIds\n",
        "\n",
        "inp_seq, inp_time, labels, itemIds = _preprocess_sess_dict(sessDict)\n",
        "print('input sequences: ', inp_seq)\n",
        "print('input times: ', inp_time)\n",
        "print('targets: ', labels)\n",
        "print('sequence: ', itemIds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPUbfre3aQ3v",
        "outputId": "37c3ccf5-c868-4644-d96b-9d0717e71b1b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input sequences:  [[214834865], [214834865, 214820225]]\n",
            "input times:  ['1396808691.422000', '1396808691.426000']\n",
            "targets:  [214820225, 214706441]\n",
            "sequence:  [214834865, 214820225, 214706441]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Khởi tạo chuỗi input và output cho toàn bộ các session\n",
        "def _preprocess_data(data_sess):\n",
        "    inp_seqs = []\n",
        "    inp_times = []\n",
        "    labels = []\n",
        "    sequences = []\n",
        "    sessIds = list(data_sess.index)\n",
        "    for sessId in sessIds:\n",
        "        sessDict = data_sess.loc[sessId]\n",
        "        inp_seq, inp_time, label, sequence = _preprocess_sess_dict(sessDict)\n",
        "        inp_seqs += inp_seq\n",
        "        inp_times += inp_time\n",
        "        labels += label\n",
        "        sequences += sequence\n",
        "    return inp_seqs, inp_times, labels, sequences\n",
        "\n",
        "train_inp_seqs, train_inp_dates, train_labs, train_sequences = _preprocess_data(train_sess)\n",
        "test_inp_seqs, test_inp_dates, test_labs, test_sequences = _preprocess_data(test_sess)\n",
        "\n",
        "train = (train_inp_seqs, train_labs)\n",
        "test = (test_inp_seqs, test_labs)\n",
        "\n",
        "print('Done.')"
      ],
      "metadata": {
        "id": "He_tN7Swaivu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c36396a-42cf-4a76-9502-058141072695"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lưu dữ liệu train/test"
      ],
      "metadata": {
        "id": "547YB5FAapcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "def _save_file(filename, obj):\n",
        "  with open(filename, 'wb') as fn:\n",
        "    pickle.dump(obj, fn)\n",
        "\n",
        "# Tạo folder yoochoose-data-4 để lưu dữ liệu train/test nếu chưa tồn tại\n",
        "if not os.path.exists('dressipi_data_train0.2'):\n",
        "  os.mkdir('dressipi_data_train0.2')\n",
        "\n",
        "# Lưu train/test\n",
        "_save_file('dressipi_data_train0.2/train02.pkl', train)\n",
        "_save_file('dressipi_data_train0.2/test02.pkl', test)"
      ],
      "metadata": {
        "id": "Kra5Au9Maotg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def _load_file(filename):\n",
        "  with open(filename, 'rb') as fn:\n",
        "    data = pickle.load(fn)\n",
        "  return data\n",
        "\n",
        "# Load dữ liệu train/test từ folder\n",
        "train = _load_file('dressipi_data_train0.2/train02.pkl')\n",
        "test = _load_file('dressipi_data_train0.2/test02.pkl')"
      ],
      "metadata": {
        "id": "xaant_vkrnja"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Khởi tạo dictionary"
      ],
      "metadata": {
        "id": "3saYIMSOsFMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Các token default\n",
        "PAD_token = 0  # token padding cho câu ngắn\n",
        "\n",
        "class Voc:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.trimmed = False\n",
        "        self.item2index = {}\n",
        "        self.item2count = {}\n",
        "        self.index2item = {PAD_token: \"PAD\"}\n",
        "        self.num_items = 1  # số lượng mặc định ban đầu là 1 ứng với PAD_token\n",
        "\n",
        "    def addSenquence(self, data):\n",
        "        for sequence in data:\n",
        "          for item in sequence:\n",
        "              self.addItem(item)\n",
        "\n",
        "    # Thêm một item vào hệ thống\n",
        "    def addItem(self, item):\n",
        "        if item not in self.item2index:\n",
        "            self.item2index[item] = self.num_items\n",
        "            self.item2count[item] = 1\n",
        "            self.index2item[self.num_items] = item\n",
        "            self.num_items += 1\n",
        "        else:\n",
        "            self.item2count[item] += 1\n",
        "\n",
        "    # Loại các item dưới ngưỡng xuất hiện min_count\n",
        "    def trim(self, min_count):\n",
        "        if self.trimmed:\n",
        "            return\n",
        "        self.trimmed = True\n",
        "\n",
        "        keep_items = []\n",
        "\n",
        "        for k, v in self.item2count.items():\n",
        "            if v >= min_count:\n",
        "                keep_items.append(k)\n",
        "\n",
        "        print('keep_items {} / {} = {:.4f}'.format(\n",
        "            len(keep_items), len(self.item2index), len(keep_items) / len(self.item2index)\n",
        "        ))\n",
        "\n",
        "        # Khởi tạo lại từ điển\n",
        "        self.item2index = {}\n",
        "        self.item2count = {}\n",
        "        self.index2item = {PAD_token: \"PAD\"}\n",
        "        self.num_items = 1\n",
        "\n",
        "        # Thêm các items vào từ điển\n",
        "        for item in keep_items:\n",
        "            self.addItem(item)\n",
        "\n",
        "    # Hàm convert sequence về chuỗi các indices\n",
        "    def _seqItem2seqIndex(self, x):\n",
        "        return [voc.item2index[item] if item in voc.item2index else 0 for item in x]"
      ],
      "metadata": {
        "id": "CbHpMcKysGcU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lấy toàn bộ list các itemIds trong các session\n",
        "from itertools import chain\n",
        "seq_targets = [train[1]] + [test[1]]\n",
        "sessionIds = list(chain.from_iterable(seq_targets))\n",
        "sessionIds = set(sessionIds)\n",
        "print('Number of sessionIds: ', len(sessionIds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrqaqhmzsLVF",
        "outputId": "ff6ba566-e038-4169-a664-0da9a0cae761"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessionIds:  19822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Khởi tạo vocabulary cho bộ dữ liệu\n",
        "voc = Voc('DictItemId')\n",
        "voc.addSenquence(seq_targets)\n",
        "\n",
        "# Convert thử nghiệm một sequence itemIds\n",
        "print('sequence of itemIds: ', train[0][7])\n",
        "print('converted indices: ', voc._seqItem2seqIndex(train[0][7]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abm4-4V2sN1G",
        "outputId": "6527e8e7-b88f-4a39-c362-4f669bf69e21"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sequence of itemIds:  [16626, 22694, 16075, 26835, 23638, 21018, 13717]\n",
            "converted indices:  [8717, 2, 3, 4, 5, 6, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Chuyển dữ liệu train, test từ item sang indices của item\n",
        "train_x_index = [voc._seqItem2seqIndex(seq) for seq in train[0]]\n",
        "test_x_index = [voc._seqItem2seqIndex(seq) for seq in test[0]]\n",
        "train_y_index = voc._seqItem2seqIndex(train[1])\n",
        "test_y_index = voc._seqItem2seqIndex(test[1])\n",
        "train_index = (train_x_index, train_y_index)\n",
        "test_index = (test_x_index, test_y_index)"
      ],
      "metadata": {
        "id": "dPPxgFmVsagN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phân chia tập Train/Test/Validation\n",
        "Từ 2 tập dữ liệu train_index và test_index ban đầu ta sẽ phân chia thành 3 tập train/test và validation như sau:\n",
        "\n",
        "Mỗi tập dữ liệu bao gồm 2 phần: input bao gồm chuỗi các itemId liên tiếp, output là itemId tiếp theo trong được khách hàng click.\n",
        "\n",
        "Dữ liệu validation được rút ra từ dữ liệu train set theo tỷ lệ được qui định tại valid_portion. Phần còn lại của train set được dữ làm tập train set mới.\n",
        "\n",
        "Dữ liệu test được tính toàn trực tiếp từ tập test set.\n",
        "\n",
        "Đối với dữ liệu input, chuỗi dữ liệu sẽ được truncate về độ dài maxlen nếu nó vượt qua maxlen."
      ],
      "metadata": {
        "id": "itMzUJP0s8iM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(root='', valid_portion=0.1, maxlen=19, sort_by_len=False, train_set=None, test_set=None):\n",
        "    \"\"\"Load dataset từ root\n",
        "    root: folder dữ liệu train, trong trường hợp train_set, test_set tồn tại thì không sử dụng train_set và test_set\n",
        "    valid_portion: tỷ lệ phân chia dữ liệu validation/train\n",
        "    maxlen: độ dài lớn nhất của sequence\n",
        "    sort_by_len: có sort theo chiều dài các session trước khi chia hay không?\n",
        "    train_set: training dataset\n",
        "    test_set:  test dataset\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the dataset\n",
        "    if train_set is None and test_set is None:\n",
        "        path_train_data = os.path.join(root, 'train.pkl')\n",
        "        path_test_data = os.path.join(root, 'test.pkl')\n",
        "        with open(path_train_data, 'rb') as f1:\n",
        "            train_set = pickle.load(f1)\n",
        "\n",
        "        with open(path_test_data, 'rb') as f2:\n",
        "            test_set = pickle.load(f2)\n",
        "\n",
        "    if maxlen:\n",
        "        new_train_set_x = []\n",
        "        new_train_set_y = []\n",
        "        # Lọc dữ liệu sequence đến maxlen\n",
        "        for x, y in zip(train_set[0], train_set[1]):\n",
        "            if len(x) < maxlen:\n",
        "                new_train_set_x.append(x)\n",
        "                new_train_set_y.append(y)\n",
        "            else:\n",
        "                new_train_set_x.append(x[:maxlen])\n",
        "                new_train_set_y.append(y)\n",
        "        train_set = (new_train_set_x, new_train_set_y)\n",
        "        del new_train_set_x, new_train_set_y\n",
        "\n",
        "        new_test_set_x = []\n",
        "        new_test_set_y = []\n",
        "        for xx, yy in zip(test_set[0], test_set[1]):\n",
        "            if len(xx) < maxlen:\n",
        "                new_test_set_x.append(xx)\n",
        "                new_test_set_y.append(yy)\n",
        "            else:\n",
        "                new_test_set_x.append(xx[:maxlen])\n",
        "                new_test_set_y.append(yy)\n",
        "        test_set = (new_test_set_x, new_test_set_y)\n",
        "        del new_test_set_x, new_test_set_y\n",
        "\n",
        "    # phân chia tập train thành train và validation\n",
        "    train_set_x, train_set_y = train_set\n",
        "    n_samples = len(train_set_x)\n",
        "    sidx = np.arange(n_samples, dtype='int32')\n",
        "    np.random.shuffle(sidx)\n",
        "    n_train = int(np.round(n_samples * (1. - valid_portion)))\n",
        "    valid_set_x = [train_set_x[s] for s in sidx[n_train:]]\n",
        "    valid_set_y = [train_set_y[s] for s in sidx[n_train:]]\n",
        "    train_set_x = [train_set_x[s] for s in sidx[:n_train]]\n",
        "    train_set_y = [train_set_y[s] for s in sidx[:n_train]]\n",
        "\n",
        "    (test_set_x, test_set_y) = test_set\n",
        "\n",
        "    # Trả về indices thứ tự độ dài của mỗi phần tử trong seq\n",
        "    def len_argsort(seq):\n",
        "        return sorted(range(len(seq)), key=lambda x: len(seq[x]))\n",
        "\n",
        "    # Sắp xếp session theo độ dài tăng dần\n",
        "    if sort_by_len:\n",
        "        sorted_index = len_argsort(test_set_x)\n",
        "        test_set_x = [test_set_x[i] for i in sorted_index]\n",
        "        test_set_y = [test_set_y[i] for i in sorted_index]\n",
        "\n",
        "        sorted_index = len_argsort(valid_set_x)\n",
        "        valid_set_x = [valid_set_x[i] for i in sorted_index]\n",
        "        valid_set_y = [valid_set_y[i] for i in sorted_index]\n",
        "\n",
        "    train = (train_set_x, train_set_y)\n",
        "    valid = (valid_set_x, valid_set_y)\n",
        "    test = (test_set_x, test_set_y)\n",
        "    return train, valid, test"
      ],
      "metadata": {
        "id": "vprh-NX3s7jT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loader\n",
        "Để streaming dữ liệu theo batch thì ta cần sử dụng class DataLoader của pytorch. Nó sẽ cho phép ta sử dụng generator để sinh dữ liệu cho từng batch huấn luyện. Do đó ta sẽ có thể huấn luyện được những mô hình từ dữ liệu có kích thước lớn hơn RAM gấp rất nhiều lần. Data Loader trong pytorch sẽ sử dụng dữ liệu là các class Dataset của pytorch như bên dưới"
      ],
      "metadata": {
        "id": "XqAlGwtitLdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class RecSysDataset(Dataset):\n",
        "    \"\"\"define the pytorch Dataset class for yoochoose and diginetica datasets.\n",
        "    \"\"\"\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        print('-'*50)\n",
        "        print('Dataset info:')\n",
        "        print('Number of sessions: {}'.format(len(data[0])))\n",
        "        print('-'*50)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        session_items = self.data[0][index]\n",
        "        target_item = self.data[1][index]\n",
        "        return session_items, target_item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data[0])"
      ],
      "metadata": {
        "id": "xyb-k3pAtIx0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hàm phụ trợ\n",
        "import torch\n",
        "\n",
        "def collate_fn(data):\n",
        "    \"\"\"\n",
        "    Hàm số này sẽ được sử dụng để pad session về max length\n",
        "    Args:\n",
        "      data: batch truyền vào\n",
        "    return:\n",
        "      batch data đã được pad length có shape maxlen x batch_size\n",
        "    \"\"\"\n",
        "    # Sort batch theo độ dài của input_sequence từ cao xuống thấp\n",
        "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "    lens = [len(sess) for sess, label in data]\n",
        "    labels = []\n",
        "    # Padding batch size\n",
        "    padded_sesss = torch.zeros(len(data), max(lens)).long()\n",
        "    for i, (sess, label) in enumerate(data):\n",
        "        padded_sesss[i,:lens[i]] = torch.LongTensor(sess)\n",
        "        labels.append(label)\n",
        "\n",
        "    # Transpose dữ liệu từ batch_size x maxlen --> maxlen x batch_size\n",
        "    padded_sesss = padded_sesss.transpose(0,1)\n",
        "    return padded_sesss, torch.tensor(labels).long(), lens"
      ],
      "metadata": {
        "id": "iIDbw8LitOiG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Metric"
      ],
      "metadata": {
        "id": "KsbuMl6ptbEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "#indices (Bxk): torch.LongTensor. Top-k indices predicted from the model\n",
        "#targets (B): torch.LongTensor. actual target indices\n",
        "\n",
        "def get_recall(indices, targets):\n",
        "    \"\"\"\n",
        "    Tính toán chỉ số recall cho một tập hợp predictions và targets\n",
        "    Args:\n",
        "        indices (Bxk): torch.LongTensor. top-k indices được dự báo từ mô hình model.\n",
        "        targets (B): torch.LongTensor. actual target indices.\n",
        "    Returns:\n",
        "        recall (float): the recall score\n",
        "    \"\"\"\n",
        "    # copy targets k lần để trở thành kích thước Bxk\n",
        "    targets = targets.view(-1, 1).expand_as(indices)\n",
        "    # print('targets', targets)\n",
        "    # so sánh targets với indices để tìm ra vị trí mà khách hàng sẽ hit.\n",
        "    hits = (targets == indices).to(device)\n",
        "    # print('hits', hits)\n",
        "    hits = hits.double()\n",
        "    if targets.size(0) == 0:\n",
        "        return 0\n",
        "    # Đếm số hit\n",
        "    n_hits = torch.sum(hits)\n",
        "    # print('n_hits', n_hits)\n",
        "    recall = n_hits / targets.size(0)\n",
        "    # print('recall check', recall)\n",
        "    # print(recall.dtype)\n",
        "    return recall\n",
        "\n",
        "\n",
        "def get_mrr(indices, targets):\n",
        "    \"\"\"\n",
        "    Tính toán chỉ số MRR cho một tập hợp predictions và targets\n",
        "    Args:\n",
        "        indices (Bxk): torch.LongTensor. top-k indices được dự báo từ mô hình model.\n",
        "        targets (B): torch.LongTensor. actual target indices.\n",
        "    Returns:\n",
        "        recall (float): the MRR score\n",
        "    \"\"\"\n",
        "    tmp = targets.view(-1, 1)\n",
        "    # print('tmp',tmp)\n",
        "    targets = tmp.expand_as(indices)\n",
        "    # print('targets', targets)\n",
        "    hits = (targets == indices).to(device)\n",
        "    # print('hits', hits)\n",
        "    hits = hits.double()\n",
        "    if hits.sum() == 0:\n",
        "      return 0\n",
        "    argsort = []\n",
        "    for i in np.arange(hits.shape[0]):\n",
        "      index_col = torch.where(hits[i, :] == 1)[0]+1\n",
        "      if index_col.shape[0] != 0:\n",
        "        argsort.append(index_col.double())\n",
        "    inv_argsort = (1/item for item in argsort)\n",
        "    mrr = sum(inv_argsort)/hits.shape[0]\n",
        "    mrr_item = mrr.item()\n",
        "    mrr = torch.tensor(mrr_item, dtype=torch.float64)\n",
        "    return mrr\n",
        "\n",
        "def get_hitrate(indices, targets):\n",
        "    #inputs: indices and targets\n",
        "    #returns: if just one item in targets hit in indices. return 1\n",
        "    # copy targets k lần để trở thành kích thước Bxk\n",
        "    targets = targets.view(-1, 1).expand_as(indices)\n",
        "    # so sánh targets với indices để tìm ra vị trí mà khách hàng sẽ hit.\n",
        "    hits = (targets == indices).to(device)\n",
        "    hits = hits.double()\n",
        "    if targets.size(0) == 0:\n",
        "        return 0\n",
        "    # Đếm số hit\n",
        "    n_hits = torch.sum(hits)\n",
        "    if n_hits == 0:\n",
        "      hitrate = 0\n",
        "    else:\n",
        "      hitrate = 1\n",
        "    #convert to torch\n",
        "    hitrate = torch.tensor(hitrate, dtype=torch.float64)\n",
        "    return hitrate\n",
        "\n",
        "\n",
        "def evaluate(logits, targets, k=20):\n",
        "    \"\"\"\n",
        "    Đánh giá model sử dụng Recall@K, MRR@K scores.\n",
        "    Args:\n",
        "        logits (B,C): torch.LongTensor. giá trị predicted logit cho itemId tiếp theo.\n",
        "        targets (B): torch.LongTensor. actual target indices.\n",
        "    Returns:\n",
        "        recall (float): the recall score\n",
        "        mrr (float): the mrr score\n",
        "    \"\"\"\n",
        "    # Tìm ra indices của topk lớn nhất các giá trị dự báo.\n",
        "    _, indices = torch.topk(logits, k, -1)\n",
        "    # print('logits', logits)\n",
        "    # print('indices', indices)\n",
        "    recall = get_recall(indices, targets)\n",
        "    mrr = get_mrr(indices, targets)\n",
        "    hitrate = get_hitrate(indices, targets)\n",
        "    # print(recall.dtype)\n",
        "    # print(mrr.dtype)\n",
        "    # print(hitrate.dtype)\n",
        "    return recall, mrr, hitrate"
      ],
      "metadata": {
        "id": "CE9JLKXMtdU-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "logits = torch.tensor([[0.1, 0.2, 0.7],\n",
        "                       [0.4, 0.1, 0.5],\n",
        "                       [0.1, 0.2, 0.7]]).to(device)\n",
        "\n",
        "targets = torch.tensor([1, 2, 2]).to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "WjaSlyNdtipX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(logits = logits, targets = targets, k = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WlX51Hhbbhw",
        "outputId": "15d7f693-67db-41f1-a530-4bb7597f5893"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1., dtype=torch.float64),\n",
              " tensor(0.8333, dtype=torch.float64),\n",
              " tensor(1., dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall, mrr, hitrate = evaluate(logits, targets, k = 2)\n",
        "print(recall)\n",
        "print('---'*5)\n",
        "print(mrr)\n",
        "print('---'*5)\n",
        "print(hitrate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGx5ZVrE1TO8",
        "outputId": "32a94c87-2d27-4d54-8317-49e461304717"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., dtype=torch.float64)\n",
            "---------------\n",
            "tensor(0.8333, dtype=torch.float64)\n",
            "---------------\n",
            "tensor(1., dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(recall.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93Cj-6lt1aN-",
        "outputId": "950a12ab-e48d-4abd-b119-ff0692966e42"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(11., 16.)\n",
        "x\n",
        "torch.topk(x, 3, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geBIUBpi3PK2",
        "outputId": "5eb1cb4d-d836-4ec8-a50b-dc1e38ed30cb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.topk(\n",
              "values=tensor([15., 14., 13.]),\n",
              "indices=tensor([4, 3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model NARM"
      ],
      "metadata": {
        "id": "bcWAlCNUdV_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class NARM(nn.Module):\n",
        "    def __init__(self, hidden_size, n_items, embedding_dim, n_layers=1, dropout=0.25):\n",
        "        super(NARM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_items = n_items\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(self.n_items, self.embedding_dim, padding_idx = 0)\n",
        "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
        "        # set bidirectional = True for bidirectional\n",
        "        # https://pytorch.org/docs/stable/nn.html?highlight=gru#torch.nn.GRU to get more information\n",
        "        self.gru = nn.GRU(input_size = hidden_size, # number of expected feature of input x\n",
        "                          hidden_size = hidden_size, # number of expected feature of hidden state\n",
        "                          num_layers = n_layers, # number of GRU layers\n",
        "                          dropout=(0 if n_layers == 1 else dropout), # dropout probability apply in encoder network\n",
        "                          bidirectional=True # one or two directions.\n",
        "                         )\n",
        "        self.emb_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_size, self.n_layers)\n",
        "        self.a_1 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
        "        self.a_2 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
        "        self.v_t = nn.Linear(self.hidden_size, 1, bias=False)\n",
        "        self.ct_dropout = nn.Dropout(0.5)\n",
        "        self.b = nn.Linear(self.embedding_dim, 2 * self.hidden_size, bias=False)\n",
        "        self.sf = nn.Softmax()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        \"\"\"\n",
        "        input_seq: Batch input_sequence. Shape: max_len x batch_size\n",
        "        input_lengths: Batch input lengths. Shape: batch_size\n",
        "        \"\"\"\n",
        "        # Step 1: Convert sequence indexes to embeddings\n",
        "        # shape: (max_length , batch_size , hidden_size)\n",
        "        embedded = self.embedding(input_seq)\n",
        "        # Pack padded batch of sequences for RNN module. Padding zero when length less than max_length of input_lengths.\n",
        "        # shape: (max_length , batch_size , hidden_size)\n",
        "        packed = pack_padded_sequence(embedded, input_lengths)\n",
        "\n",
        "        # Step 2: Forward packed through GRU\n",
        "        # outputs is output of final GRU layer\n",
        "        # hidden is concatenate of all hidden states corresponding with each time step.\n",
        "        # outputs shape: (max_length , batch_size , hidden_size x num_directions)\n",
        "        # hidden shape: (n_layers x num_directions , batch_size , hidden_size)\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        # Unpack padding. Revert of pack_padded_sequence\n",
        "        # outputs shape: (max_length , batch_size , hidden_size x num_directions)\n",
        "        outputs, length = pad_packed_sequence(outputs)\n",
        "\n",
        "        # Step 3: Global Encoder & Local Encoder\n",
        "        # num_directions = 1 -->\n",
        "        # outputs shape:(max_length , batch_size , hidden_size)\n",
        "        # hidden shape: (n_layers , batch_size , hidden_size)\n",
        "        # lấy hidden state tại time step cuối cùng\n",
        "        ht = hidden[-1]\n",
        "        # reshape outputs\n",
        "        outputs = outputs.permute(1, 0, 2) # [batch_size, max_length, hidden_size]\n",
        "        c_global = ht\n",
        "        # Flatten outputs thành shape: [batch_size, max_length, hidden_size]\n",
        "        gru_output_flatten = outputs.contiguous().view(-1, self.hidden_size)\n",
        "        # Thực hiện một phép chiếu linear projection để tạo các latent variable có shape [batch_size, max_length, hidden_size]\n",
        "        q1 = self.a_1(gru_output_flatten).view(outputs.size())\n",
        "        # Thực hiện một phép chiếu linear projection để tạo các latent variable có shape [batch_size, max_length, hidden_size]\n",
        "        q2 = self.a_2(ht)\n",
        "        # Ma trận mask đánh dấu vị trí khác 0 trên padding sequence.\n",
        "        mask = torch.where(input_seq.permute(1, 0) > 0, torch.tensor([1.], device = self.device), torch.tensor([0.], device = self.device)) # batch_size x max_len\n",
        "        # Điều chỉnh shape\n",
        "        q2_expand = q2.unsqueeze(1).expand_as(q1) # shape [batch_size, max_len, hidden_size]\n",
        "        q2_masked = mask.unsqueeze(2).expand_as(q1) * q2_expand # batch_size x max_len x hidden_size\n",
        "        # Tính trọng số alpha đo lường similarity giữa các hidden state\n",
        "        alpha = self.v_t(torch.sigmoid(q1 + q2_masked).view(-1, self.hidden_size)).view(mask.size()) # batch_size x max_len\n",
        "        alpha_exp = alpha.unsqueeze(2).expand_as(outputs) # batch_size x max_len x hidden_size\n",
        "        # Tính linear combinition của các hidden state\n",
        "        c_local = torch.sum(alpha_exp * outputs, 1) # (batch_size x hidden_size)\n",
        "\n",
        "        # Véc tơ combinition tổng hợp\n",
        "        c_t = torch.cat([c_local, c_global], 1) # batch_size x (2*hidden_size)\n",
        "        c_t = self.ct_dropout(c_t)\n",
        "        # Tính scores\n",
        "\n",
        "        # Step 4: Decoder\n",
        "        # embedding cho toàn bộ các item\n",
        "        item_indices = torch.arange(self.n_items).to(device) # 1 x n_items\n",
        "        item_embs = self.embedding(item_indices) # n_items x embedding_dim\n",
        "        # reduce dimension by bi-linear projection\n",
        "        B = self.b(item_embs).permute(1, 0) # (2*hidden_size) x n_items\n",
        "        scores = torch.matmul(c_t, B) # batch_size x n_items\n",
        "        # scores = self.sf(scores)\n",
        "        return scores"
      ],
      "metadata": {
        "id": "XsuSpwf6dXLQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Kiểm tra model NARM\n",
        "# Thử nghiệm model bằng cách giả lập 1 input và thực hiện quá trình feed forward\n",
        "from torch import nn\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "hidden_size = 3\n",
        "n_layers = 7\n",
        "# embedding = nn.Embedding(11000, hidden_size)\n",
        "input_variable = torch.tensor([[  66,  369,   66, 1272],\n",
        "                                [ 567,  183,   28,  616],\n",
        "                                [ 392, 1558, 1143,  175],\n",
        "                                [ 394,   31,   31, 5558],\n",
        "                                [   0,    0,    0,    0]]).to(device)\n",
        "\n",
        "lengths =  torch.tensor([5, 5, 5, 5]).to(device)\n",
        "print('input_seq: \\n', input_variable)\n",
        "print('input_lengths: \\n', lengths)\n",
        "model_test = NARM(hidden_size = hidden_size, n_items  = 100000, embedding_dim = 100, n_layers=1, dropout=0.25).to(device)\n",
        "print('model phrase: \\n', model_test)\n",
        "scores = model_test.forward(input_seq = input_variable, input_lengths = lengths)\n",
        "print('probability distribution: ', scores.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiCxOA6Jdbqm",
        "outputId": "97948ce4-a442-451c-cafc-701a157f06fe"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_seq: \n",
            " tensor([[  66,  369,   66, 1272],\n",
            "        [ 567,  183,   28,  616],\n",
            "        [ 392, 1558, 1143,  175],\n",
            "        [ 394,   31,   31, 5558],\n",
            "        [   0,    0,    0,    0]])\n",
            "input_lengths: \n",
            " tensor([5, 5, 5, 5])\n",
            "model phrase: \n",
            " NARM(\n",
            "  (embedding): Embedding(100000, 100, padding_idx=0)\n",
            "  (gru): GRU(100, 3)\n",
            "  (emb_dropout): Dropout(p=0.25, inplace=False)\n",
            "  (a_1): Linear(in_features=3, out_features=3, bias=False)\n",
            "  (a_2): Linear(in_features=3, out_features=3, bias=False)\n",
            "  (v_t): Linear(in_features=3, out_features=1, bias=False)\n",
            "  (ct_dropout): Dropout(p=0.5, inplace=False)\n",
            "  (b): Linear(in_features=100, out_features=6, bias=False)\n",
            "  (sf): Softmax(dim=None)\n",
            ")\n",
            "probability distribution:  torch.Size([4, 100000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Validation"
      ],
      "metadata": {
        "id": "Dxql6QPAtoDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(valid_loader, model):\n",
        "    model.eval()\n",
        "    recalls = []\n",
        "    mrrs = []\n",
        "    hitrates = []\n",
        "    with torch.no_grad():\n",
        "        for seq, target, lens in valid_loader:\n",
        "            seq = seq.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            outputs = model(seq, lens)\n",
        "\n",
        "            logits = F.softmax(outputs, dim = 1)\n",
        "            recall, mrr, hitrate = evaluate(logits, target, k = args['topk'])\n",
        "            recalls.append(recall)\n",
        "            mrrs.append(mrr)\n",
        "            hitrates.append(hitrate)\n",
        "\n",
        "    mean_recall = torch.mean(torch.stack(recalls))\n",
        "    # mean_mrr = torch.mean(torch.stack(mrrs))\n",
        "    mean_mrr = torch.mean(torch.stack([torch.tensor(float(mrr)) for mrr in mrrs]))\n",
        "    mean_hitrate = torch.mean(torch.stack(hitrates))\n",
        "    return mean_recall, mean_mrr, mean_hitrate"
      ],
      "metadata": {
        "id": "qCNFThZftnt6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training model"
      ],
      "metadata": {
        "id": "7ysBrZ0qtu1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from os.path import join\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.autograd import Variable\n",
        "from torch.backends import cudnn\n",
        "\n",
        "args = {\n",
        "    'dataset_path':'../input/dressipi_recsys2022_dataset/train_sessions.csv',\n",
        "    'batch_size': 256,\n",
        "    'hidden_size': 100,\n",
        "    'embed_dim': 50,\n",
        "    'epoch': 5,\n",
        "    'lr':0.001,\n",
        "    'lr_dc':0.1,\n",
        "    'lr_dc_step':80,\n",
        "    'test':None,\n",
        "    'topk':10,\n",
        "    'valid_portion':0.1\n",
        "}\n",
        "\n",
        "here = os.path.dirname(os.getcwd())\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def main():\n",
        "    print('Loading data...')\n",
        "    train_data, valid_data, test_data = load_data(train_set=train_index, test_set=test_index)\n",
        "    train_data = RecSysDataset(train_data)\n",
        "    valid_data = RecSysDataset(valid_data)\n",
        "    test_data = RecSysDataset(test_data)\n",
        "    train_loader = DataLoader(train_data, batch_size = args['batch_size'], shuffle = True, collate_fn = collate_fn)\n",
        "    valid_loader = DataLoader(valid_data, batch_size = args['batch_size'], shuffle = False, collate_fn = collate_fn)\n",
        "    test_loader = DataLoader(test_data, batch_size = args['batch_size'], shuffle = False, collate_fn = collate_fn)\n",
        "    print('Complete load data!')\n",
        "    n_items = voc.num_items\n",
        "    model = NARM(hidden_size = args['hidden_size'], n_items = n_items, embedding_dim = args['embed_dim'], n_layers=2, dropout=0.25).to(device)\n",
        "    print('complete load model!')\n",
        "\n",
        "    if args['test'] == 'store_true':\n",
        "        ckpt = torch.load('latest_checkpoint.pth.tar')\n",
        "        model.load_state_dict(ckpt['state_dict'])\n",
        "        recall, mrr, hitrate = validate(test_loader, model)\n",
        "        print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}, HitRate@{}: {:.4f}\".format(args['topk'], recall, args['topk'], mrr, args['topk'], hitrate))\n",
        "        return model\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), args['lr'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = StepLR(optimizer, step_size = args['lr_dc_step'], gamma = args['lr_dc'])\n",
        "\n",
        "    print('start training!')\n",
        "    for epoch in tqdm(range(args['epoch'])):\n",
        "        # train for one epoch\n",
        "        trainForEpoch(train_loader, model, optimizer, epoch, args['epoch'], criterion, log_aggr = 1000)\n",
        "        scheduler.step(epoch = epoch)\n",
        "        recall, mrr, hitrate = validate(valid_loader, model)\n",
        "        print('Epoch {} validation: Recall@{}: {:.4f}; MRR@{}: {:.4f}; HitRate@{}: {:.4f}\\n.  '.format(epoch, args['topk'], recall, args['topk'], mrr, args['topk'], hitrate, args['topk']))\n",
        "        print('mrr', mrr)\n",
        "        print('hitrate',hitrate)\n",
        "\n",
        "        # store best loss and save a model checkpoint\n",
        "        ckpt_dict = {\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "\n",
        "        torch.save(ckpt_dict, 'latest_checkpoint.pth.tar')\n",
        "    return model\n",
        "\n",
        "\n",
        "def trainForEpoch(train_loader, model, optimizer, epoch, num_epochs, criterion, log_aggr=1000):\n",
        "    model.train()\n",
        "\n",
        "    sum_epoch_loss = 0\n",
        "\n",
        "    start = time.time()\n",
        "    for i, (seq, target, lens) in enumerate(train_loader):\n",
        "        seq = seq.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(seq, lens)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_val = loss.item()\n",
        "        sum_epoch_loss += loss_val\n",
        "\n",
        "        iter_num = epoch * len(train_loader) + i + 1\n",
        "\n",
        "        if i % log_aggr == 0:\n",
        "            print('[TRAIN] epoch %d/%d  observation %d/%d batch loss: %.4f (avg %.4f) (%.2f im/s)'\n",
        "                % (epoch + 1, num_epochs, i, len(train_loader), loss_val, sum_epoch_loss / (i + 1),\n",
        "                  len(seq) / (time.time() - start)))\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "model = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff7pHgPZtud_",
        "outputId": "b409b145-922b-4cef-ff9d-153c6198d767"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "--------------------------------------------------\n",
            "Dataset info:\n",
            "Number of sessions: 695455\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Dataset info:\n",
            "Number of sessions: 77273\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Dataset info:\n",
            "Number of sessions: 375638\n",
            "--------------------------------------------------\n",
            "Complete load data!\n",
            "complete load model!\n",
            "start training!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN] epoch 1/5  observation 0/2717 batch loss: 11.1510 (avg 11.1510) (63.51 im/s)\n",
            "[TRAIN] epoch 1/5  observation 1000/2717 batch loss: 9.5489 (avg 9.7968) (205.41 im/s)\n",
            "[TRAIN] epoch 1/5  observation 2000/2717 batch loss: 9.2343 (avg 9.5823) (214.00 im/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            " 20%|██        | 1/5 [04:42<18:50, 282.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 validation: Recall@10: 0.0123; MRR@10: 0.0046; HitRate@10: 0.9536\n",
            ".  \n",
            "mrr tensor(0.0046)\n",
            "hitrate tensor(0.9536, dtype=torch.float64)\n",
            "[TRAIN] epoch 2/5  observation 0/2717 batch loss: 9.1101 (avg 9.1101) (132.50 im/s)\n",
            "[TRAIN] epoch 2/5  observation 1000/2717 batch loss: 9.1205 (avg 9.1672) (216.62 im/s)\n",
            "[TRAIN] epoch 2/5  observation 2000/2717 batch loss: 9.0373 (avg 9.1453) (218.53 im/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [09:19<13:57, 279.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 validation: Recall@10: 0.0157; MRR@10: 0.0061; HitRate@10: 0.9834\n",
            ".  \n",
            "mrr tensor(0.0061)\n",
            "hitrate tensor(0.9834, dtype=torch.float64)\n",
            "[TRAIN] epoch 3/5  observation 0/2717 batch loss: 9.0141 (avg 9.0141) (117.56 im/s)\n",
            "[TRAIN] epoch 3/5  observation 1000/2717 batch loss: 8.8892 (avg 8.9099) (189.74 im/s)\n",
            "[TRAIN] epoch 3/5  observation 2000/2717 batch loss: 8.8350 (avg 8.8449) (216.64 im/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [13:55<09:15, 277.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 validation: Recall@10: 0.0236; MRR@10: 0.0086; HitRate@10: 0.9934\n",
            ".  \n",
            "mrr tensor(0.0086)\n",
            "hitrate tensor(0.9934, dtype=torch.float64)\n",
            "[TRAIN] epoch 4/5  observation 0/2717 batch loss: 8.7457 (avg 8.7457) (129.78 im/s)\n",
            "[TRAIN] epoch 4/5  observation 1000/2717 batch loss: 8.6548 (avg 8.6121) (131.06 im/s)\n",
            "[TRAIN] epoch 4/5  observation 2000/2717 batch loss: 8.5326 (avg 8.5858) (195.38 im/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [18:36<04:38, 278.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 validation: Recall@10: 0.0298; MRR@10: 0.0107; HitRate@10: 1.0000\n",
            ".  \n",
            "mrr tensor(0.0107)\n",
            "hitrate tensor(1., dtype=torch.float64)\n",
            "[TRAIN] epoch 5/5  observation 0/2717 batch loss: 8.2836 (avg 8.2836) (143.03 im/s)\n",
            "[TRAIN] epoch 5/5  observation 1000/2717 batch loss: 8.3925 (avg 8.4325) (215.25 im/s)\n",
            "[TRAIN] epoch 5/5  observation 2000/2717 batch loss: 8.2841 (avg 8.4065) (217.97 im/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [23:16<00:00, 279.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 validation: Recall@10: 0.0353; MRR@10: 0.0122; HitRate@10: 1.0000\n",
            ".  \n",
            "mrr tensor(0.0122)\n",
            "hitrate tensor(1., dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()\n",
        "# chứa 'latest_checkpoint.pth.tar'"
      ],
      "metadata": {
        "id": "2pJIrilqvn0L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df424d8d-dc08-4a5d-84f0-375991f866dc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'dressipi_recsys2022_dataset',\n",
              " 'latest_checkpoint.pth.tar',\n",
              " 'dressipi_recsys2022_datasets.zip',\n",
              " 'dressipi_data_train0.2',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "PATH = 'latest_checkpoint.pth.tar'\n",
        "model = NARM(hidden_size = args['hidden_size'], n_items = 19823, embedding_dim = args['embed_dim'], n_layers=2, dropout=0.25).to(device)\n",
        "optimizer = optim.Adam(params = model.parameters(), lr=0.001)\n",
        "\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "epoch = checkpoint['epoch']\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "Ty19p9tXvrQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ccdfe1e-1943-4c71-83f2-538dfe1a0ff7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NARM(\n",
              "  (embedding): Embedding(19823, 50, padding_idx=0)\n",
              "  (gru): GRU(50, 100, num_layers=2)\n",
              "  (emb_dropout): Dropout(p=0.25, inplace=False)\n",
              "  (a_1): Linear(in_features=100, out_features=100, bias=False)\n",
              "  (a_2): Linear(in_features=100, out_features=100, bias=False)\n",
              "  (v_t): Linear(in_features=100, out_features=1, bias=False)\n",
              "  (ct_dropout): Dropout(p=0.5, inplace=False)\n",
              "  (b): Linear(in_features=50, out_features=200, bias=False)\n",
              "  (sf): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lựa chọn ngẫu nhiên một session trên test\n",
        "import numpy as np\n",
        "i = np.random.randint(0, len(test_index[0]))\n",
        "x = [test_index[0][i]]\n",
        "y = [test_index[1][i]]\n",
        "print('item indexes sequence input: ', x)\n",
        "print('item index next output: ', y)"
      ],
      "metadata": {
        "id": "0XaCsKXUvsUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb69c46-b67b-45ca-d4b7-4de56ff6724b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "item indexes sequence input:  [[14384]]\n",
            "item index next output:  [5019]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Khởi tạo test_loader để biến đổi dữ liệu session đưa vào mô hình\n",
        "test_data = RecSysDataset([x, y])\n",
        "test_loader = DataLoader(test_data, batch_size = args['batch_size'], shuffle = False, collate_fn = collate_fn)\n",
        "\n",
        "# Step 2: Dự báo các indice tiếp theo mà khách hàng có khả năng click\n",
        "def _preddict(loader, model):\n",
        "    model.eval()\n",
        "    recalls = []\n",
        "    mrrs = []\n",
        "    j = 1\n",
        "    with torch.no_grad():\n",
        "      for seq, target, lens in loader:\n",
        "        seq = seq.to(device)\n",
        "        target = target.to(device)\n",
        "        outputs = model(seq, lens)\n",
        "        logits = F.softmax(outputs, dim = 1)\n",
        "        _, indices = torch.topk(logits, 20, -1)\n",
        "        print('Is next clicked item in top 20 suggestions: ', (target in indices))\n",
        "        print('Top 20 next item indices suggested: ')\n",
        "    return indices\n",
        "\n",
        "_preddict(test_loader, model)"
      ],
      "metadata": {
        "id": "M5uHJ7w2vu6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce090d5f-9d30-4d7e-90d6-058b81ce1c03"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Dataset info:\n",
            "Number of sessions: 1\n",
            "--------------------------------------------------\n",
            "Is next clicked item in top 20 suggestions:  False\n",
            "Top 20 next item indices suggested: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3475, 2089, 2279, 3224, 2153, 2317,  533, 6602, 1203,  717,  330, 2352,\n",
              "          972, 4921, 1579,  430, 4532,  855, 4061,  520]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}