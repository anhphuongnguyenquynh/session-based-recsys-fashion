{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9GEtCX3BEXUq",
        "dMzw8c1OEjtO",
        "j9HtbRNzEhVQ",
        "KTXN2XITbcNA",
        "D-OzRPoKdgl2"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import libraries"
      ],
      "metadata": {
        "id": "9GEtCX3BEXUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset\n",
        "from torchtext.vocab import vocab\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNs2CQ2QE6sL",
        "outputId": "9854cdbe-2b9e-46a5-c84d-a17856fab9aa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Datasets"
      ],
      "metadata": {
        "id": "dMzw8c1OEjtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the data (session_id, item_id, date, Datetime, Timestamp)\n",
        "url01 = 'https://raw.githubusercontent.com/anhphuongnguyenquynh/session-based-recsys-fashion/main/dataset_filtered/train_session01_seq.csv'"
      ],
      "metadata": {
        "id": "aoZTIz0mcWeV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset01 = pd.read_csv(url01, index_col = 0, parse_dates=[\"date\"])\n",
        "dataset01 = dataset01.dropna()\n",
        "dataset01 = dataset01.reset_index()\n",
        "#fraction\n",
        "dataset = dataset01.sample(frac=1)\n",
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RvQUj53cX-5",
        "outputId": "a73a26b5-d509-4f4e-85a5-23f8d9c94a5a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(516944, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter item less than 5 interactions\n",
        "df_item_count = dataset[['item_id', 'session_id']].groupby('item_id').count().sort_values(by = 'session_id', ascending = False)\n",
        "df_item_count.columns = ['CountItemId']\n",
        "df_item_count_5 = df_item_count[df_item_count['CountItemId'] < 5]\n",
        "# remove item_id less than 5 interactions\n",
        "dataset = dataset[~dataset['item_id'].isin(list(df_item_count_5.index))]"
      ],
      "metadata": {
        "id": "7lKOib--cZcA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter session less than 2 iteractions\n",
        "df_session_count = dataset[['item_id', 'session_id']].groupby('session_id').count().sort_values(by = 'item_id', ascending = False)\n",
        "df_session_count.columns = ['items_in_session']\n",
        "df_session_count_2 = df_session_count[df_session_count['items_in_session'] < 2]\n",
        "# remove session_id less than 2 interactions\n",
        "dataset = dataset[~dataset['session_id'].isin(list(df_session_count_2.index))]"
      ],
      "metadata": {
        "id": "8LwOiReOcgwv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-u9xNRHchXo",
        "outputId": "70d0f507-f851-4faf-f2fd-fb2a61185edf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(253678, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unique item_id in dataset\n",
        "unique_item_id = dataset['item_id'].unique()"
      ],
      "metadata": {
        "id": "PZB7PxCccrtA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preventing ids to be written as integer or float data type\n",
        "dataset[\"session_id\"] = dataset[\"session_id\"].apply(lambda x: f\"session_{x}\")\n",
        "\n",
        "dataset[\"item_id\"] = dataset[\"item_id\"].apply(lambda x: f\"item_{x}\")"
      ],
      "metadata": {
        "id": "6KAXDY9gXk7k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Vocabulary"
      ],
      "metadata": {
        "id": "KTXN2XITbcNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#list of unique item ids\n",
        "item_ids = dataset.item_id.unique()\n",
        "\n",
        "#Counter is used to feed items to item_vocab\n",
        "item_counter = Counter(item_ids)\n",
        "\n",
        "#Genarting vocabulary\n",
        "item_vocab = vocab(item_counter, specials=['<unk>'])\n",
        "\n",
        "#For indexing input ids\n",
        "item_vocab_stoi = item_vocab.get_stoi()\n",
        "\n",
        "#Session_id vocab\n",
        "session_ids = dataset.session_id.unique()\n",
        "session_counter = Counter(session_ids)\n",
        "session_vocab = vocab(session_counter, specials=['<unk>'])\n",
        "session_vocab_stoi = session_vocab.get_stoi()"
      ],
      "metadata": {
        "id": "l8RxfgN7ba70"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Config"
      ],
      "metadata": {
        "id": "j9HtbRNzEhVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'num_items': len(item_vocab), #num_items + 1\n",
        "    'num_sessions': len(session_vocab), #13542 +1\n",
        "    'embedding_dim': 128,\n",
        "    'hidden_d': 128,\n",
        "    'trm_layers': 2,\n",
        "    'n_head': 2,\n",
        "    'dropout': 0.2,\n",
        "    'lr': 0.1,\n",
        "    'batch_size': 256,\n",
        "    'epochs': 5,\n",
        "    'label_smoothing': 0.1,\n",
        "    'topk': 20\n",
        "}\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MpVwDHHGCTn",
        "outputId": "6882140a-268b-4947-caac-7a4bea911243"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing Data"
      ],
      "metadata": {
        "id": "D-OzRPoKdgl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Group by session_id after sort_values by timestamp\n",
        "sessions_groups = dataset.sort_values(by=[\"timestamp\"]).groupby(\"session_id\")\n",
        "sessions_train = pd.DataFrame(data = {\n",
        "        \"session_id\": list(sessions_groups.groups.keys()),\n",
        "        \"month\" : list(sessions_groups.month.unique().explode()),\n",
        "        \"weekYear\" : list(sessions_groups.weekYear.unique().explode()),\n",
        "        \"season\" : list(sessions_groups.season.unique().explode()),\n",
        "        \"item_ids\": list(sessions_groups.item_id.apply(list)),\n",
        "        \"durations\": list(sessions_groups.duration.apply(list)),\n",
        "        \"timestamps\": list(sessions_groups.timestamp.apply(list)),\n",
        "    })"
      ],
      "metadata": {
        "id": "xCW2TGTukiid"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 6\n",
        "step = 2\n",
        "def create_sequences(values, sequence, step):\n",
        "  start_idx = 0\n",
        "  sec_list = []\n",
        "  #Handle case < sequence:\n",
        "  if len(values) < sequence:\n",
        "    values = values * 2\n",
        "  #Handle case >= sequence:\n",
        "  while True:\n",
        "    end_idx = start_idx + sequence\n",
        "    sec = values[start_idx:end_idx]\n",
        "    start_idx += step\n",
        "    if end_idx >= len(values):\n",
        "      sec = values[-sequence:]\n",
        "      sec_list.append(sec)\n",
        "      break\n",
        "    sec_list.append(sec)\n",
        "  return sec_list"
      ],
      "metadata": {
        "id": "6Kh59iQnklzG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sessions_train[\"item_ids\"] = sessions_train[\"item_ids\"].apply(\n",
        "    lambda values: create_sequences(\n",
        "        values,sequence_length, step))\n",
        "\n",
        "sessions_train[\"durations\"] = sessions_train[\"durations\"].apply(\n",
        "    lambda values: create_sequences(\n",
        "        values,sequence_length, step))\n",
        "\n",
        "sessions_train = sessions_train.drop(columns = [\"timestamps\"])\n",
        "\n",
        "sessions_train = sessions_train.explode(column=[\"item_ids\", \"durations\"]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "RxbZgGDakqQS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop weekYear and season\n",
        "#convert type column month to string\n",
        "sessions_train[\"month\"] = sessions_train[\"month\"].astype(str)\n",
        "sessions_train = sessions_train.drop(columns = [\"weekYear\", \"season\"])\n",
        "sessions_train.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "496q9iyHkw3o",
        "outputId": "735f7630-c61b-438f-ef55-c098118f79f8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          session_id month                                           item_ids  \\\n",
              "0  session_1000066.0  10.0  [item_22239.0, item_10408.0, item_15687.0, ite...   \n",
              "1  session_1000097.0  12.0  [item_21532.0, item_17992.0, item_17151.0, ite...   \n",
              "2  session_1000109.0   5.0  [item_23774.0, item_15429.0, item_23774.0, ite...   \n",
              "3  session_1000118.0   4.0  [item_23272.0, item_18125.0, item_18326.0, ite...   \n",
              "4  session_1000220.0   9.0  [item_12816.0, item_18743.0, item_12816.0, ite...   \n",
              "\n",
              "                                durations  \n",
              "0  [1.0, 1.0, 34975.0, 1.0, 1.0, 34975.0]  \n",
              "1          [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  \n",
              "2                    [1.0, 1.0, 1.0, 1.0]  \n",
              "3      [1.0, 1.0, 120.0, 1.0, 1.0, 120.0]  \n",
              "4                    [1.0, 1.0, 1.0, 1.0]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62d941bd-3876-45e0-98e1-39740e23607f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session_id</th>\n",
              "      <th>month</th>\n",
              "      <th>item_ids</th>\n",
              "      <th>durations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>session_1000066.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>[item_22239.0, item_10408.0, item_15687.0, ite...</td>\n",
              "      <td>[1.0, 1.0, 34975.0, 1.0, 1.0, 34975.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>session_1000097.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>[item_21532.0, item_17992.0, item_17151.0, ite...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>session_1000109.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[item_23774.0, item_15429.0, item_23774.0, ite...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>session_1000118.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>[item_23272.0, item_18125.0, item_18326.0, ite...</td>\n",
              "      <td>[1.0, 1.0, 120.0, 1.0, 1.0, 120.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>session_1000220.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>[item_12816.0, item_18743.0, item_12816.0, ite...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62d941bd-3876-45e0-98e1-39740e23607f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-62d941bd-3876-45e0-98e1-39740e23607f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-62d941bd-3876-45e0-98e1-39740e23607f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1b171b83-2c70-4c9e-9acf-51dd615db412\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b171b83-2c70-4c9e-9acf-51dd615db412')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1b171b83-2c70-4c9e-9acf-51dd615db412 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sessions_train"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train split data test"
      ],
      "metadata": {
        "id": "n0eqo3qwclxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train split data test\n",
        "random_selection = np.random.rand(len(sessions_train.index)) <= 0.85\n",
        "train_data = sessions_train[random_selection]\n",
        "test_data = sessions_train[~random_selection]"
      ],
      "metadata": {
        "id": "xPiZzPu3clNA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_raw = train_data[[\"session_id\", \"item_ids\"]].values\n",
        "test_data_raw = test_data[[\"session_id\", \"item_ids\"]].values"
      ],
      "metadata": {
        "id": "00KRdNg_WFPE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_raw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVIdYx3OZZiu",
        "outputId": "1f6609c9-96ff-4235-b445-e4b1a1baa3fa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['session_1000066.0',\n",
              "        list(['item_22239.0', 'item_10408.0', 'item_15687.0', 'item_22239.0', 'item_10408.0', 'item_15687.0'])],\n",
              "       ['session_1000097.0',\n",
              "        list(['item_21532.0', 'item_17992.0', 'item_17151.0', 'item_21532.0', 'item_17992.0', 'item_17151.0'])],\n",
              "       ['session_1000109.0',\n",
              "        list(['item_23774.0', 'item_15429.0', 'item_23774.0', 'item_15429.0'])],\n",
              "       ...,\n",
              "       ['session_999951.0',\n",
              "        list(['item_20087.0', 'item_23689.0', 'item_3499.0', 'item_20087.0', 'item_23689.0', 'item_3499.0'])],\n",
              "       ['session_999990.0',\n",
              "        list(['item_18764.0', 'item_26067.0', 'item_6548.0', 'item_13620.0', 'item_18764.0', 'item_26067.0'])],\n",
              "       ['session_999990.0',\n",
              "        list(['item_6548.0', 'item_13620.0', 'item_18764.0', 'item_26067.0', 'item_6548.0', 'item_13620.0'])]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Input for model and Data Loader"
      ],
      "metadata": {
        "id": "iaOSDgjEEqNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch Dataset for session interactions\n",
        "class ItemSeqDataset(Dataset):\n",
        "    # Initialize dataset\n",
        "    def __init__(self, data, item_vocab_stoi, session_vocab_stoi):\n",
        "        self.data = data\n",
        "\n",
        "        self.item_vocab_stoi = item_vocab_stoi\n",
        "        self.session_vocab_stoi = session_vocab_stoi\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    # Fetch data from the dataset\n",
        "    def __getitem__(self, idx):\n",
        "        session, item_sequence = self.data[idx]\n",
        "        # Directly index into the vocabularies\n",
        "        item_data = [self.item_vocab_stoi[item] for item in item_sequence]\n",
        "        session_data = self.session_vocab_stoi[session]\n",
        "        return torch.tensor(item_data), torch.tensor(session_data)\n",
        "\n",
        "\n",
        "# Collate function and padding\n",
        "def collate_batch(batch):\n",
        "    item_list = [item[0] for item in batch]\n",
        "    session_list = [item[1] for item in batch]\n",
        "    return pad_sequence(item_list, padding_value=item_vocab_stoi['<unk>'], batch_first=True), torch.stack(session_list)"
      ],
      "metadata": {
        "id": "v3DnrxWVk-ab"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = config['batch_size']\n",
        "# Create instances of your Dataset for each set\n",
        "train_dataset = ItemSeqDataset(train_data_raw, item_vocab_stoi, session_vocab_stoi)\n",
        "val_dataset = ItemSeqDataset(test_data_raw, item_vocab_stoi, session_vocab_stoi)\n",
        "# Create DataLoaders\n",
        "train_iter = DataLoader(train_dataset, batch_size=config['batch_size'],\n",
        "                        shuffle=True, collate_fn=collate_batch)\n",
        "val_iter = DataLoader(val_dataset, batch_size=config['batch_size'],\n",
        "                      shuffle=False, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "IJp8kDerlJAA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Architecture"
      ],
      "metadata": {
        "id": "E5Isq7itEsXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "\n",
        "        # `div_term` is used in the calculation of the sinusoidal values.\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # Initializing positional encoding matrix with zeros.\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "\n",
        "        # Calculating the positional encodings.\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "Maur16o_EztQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, num_items: int, num_session: int, d_model: int, nhead: int, d_hid: int,\n",
        "                 nlayers: int, dropout: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        # positional encoder\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "\n",
        "        # Multihead attention mechanism.\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "\n",
        "        # Embedding layers\n",
        "        self.item_embedding = nn.Embedding(num_items, d_model)\n",
        "        self.session_embedding = nn.Embedding(num_session, d_model)\n",
        "\n",
        "        # Defining the size of the input to the model.\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Linear layer to map the output toitem vocabulary.\n",
        "        self.linear = nn.Linear(2*d_model, num_items)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        # Initializing the weights of the embedding and linear layers.\n",
        "        initrange = 0.1\n",
        "        self.item_embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.session_embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.linear.bias.data.zero_()\n",
        "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src: Tensor, session: Tensor, src_mask: Tensor = None) -> Tensor:\n",
        "        # Embedding item ids and sessionid\n",
        "        #output item_embed (batch_size, sequence length, self.d_model)\n",
        "        #multiply with math.sqrt(self.d_model) -> scaling operation used in transformer models for stablize the training process\n",
        "        item_embed = self.item_embedding(src) * math.sqrt(self.d_model) #item_embed: [batch_size, 3, embed_dim = 128]\n",
        "        session_embed = self.session_embedding(session) * math.sqrt(self.d_model) #session_embed: [batch_size, 1, embed_dim = 128]\n",
        "\n",
        "        # positional encoding\n",
        "        item_embed = self.pos_encoder(item_embed) #item_embed pe: [batch_size, 3, embed_dim = 128]\n",
        "\n",
        "        # generating output with final layers\n",
        "        output = self.transformer_encoder(item_embed, src_mask) #output: [batch_size, 3, embed_dim = 128]\n",
        "\n",
        "        # Expand session_embed tensor along the sequence length dimension\n",
        "        session_embed = session_embed.expand(-1, output.size(1), -1) #session_embed: [batch_size, 3, embed_dim = 128]\n",
        "\n",
        "        # Concatenate session embeddings with transformer output\n",
        "        output = torch.cat((output, session_embed), dim=-1) #output: [batch_size, 3, embed_dim *2]\n",
        "\n",
        "        output = self.linear(output) #output linear: [batch_size, 3, num_items]\n",
        "        return output"
      ],
      "metadata": {
        "id": "LSPzeBlKkCcw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "1OJX1E0iEv18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerModel(num_items = config['num_items'],\n",
        "                         num_session = config['num_sessions'],\n",
        "                         d_model = config['embedding_dim'],\n",
        "                         nhead = config['n_head'],\n",
        "                         d_hid = config['hidden_d'],\n",
        "                         nlayers = config['trm_layers'],\n",
        "                         dropout = config['dropout'])\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=config['label_smoothing'])\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = config['lr'])\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CzjR4StaU5D",
        "outputId": "4c0e42fa-d02e-45c1-cf57-242f1dfdb60d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CShGENSa0C_",
        "outputId": "8e1c6a2b-7e07-4bf7-dc0e-a951caf6cfdb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerModel(\n",
            "  (pos_encoder): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "  )\n",
            "  (transformer_encoder): TransformerEncoder(\n",
            "    (layers): ModuleList(\n",
            "      (0-1): 2 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.2, inplace=False)\n",
            "        (dropout2): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (item_embedding): Embedding(14576, 128)\n",
            "  (session_embedding): Embedding(99352, 128)\n",
            "  (linear): Linear(in_features=256, out_features=14576, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train one epoch"
      ],
      "metadata": {
        "id": "iq3f-Z3kbL8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model: nn.Module, train_iter, epoch) -> None:\n",
        "    model.train()\n",
        "    total_loss = 0.\n",
        "    log_interval = 200\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, (item_data, session_data) in enumerate(train_iter):\n",
        "        # Load item sequence and session id\n",
        "        item_data, session_data = item_data.to(device), session_data.to(device) #item_data [batch_size, seq_length], session_data [batch_size]: list of session_id\n",
        "        session_data = session_data.reshape(-1, 1) #[[session1], [session2]...] reshape session_data [batch_size, 1]\n",
        "\n",
        "        # Split item sequence to inputs and targets\n",
        "        inputs, targets = item_data[:, :-1], item_data[:, 1:] #if max = 4: inputs[1,2,3]. Inputs [batch_size, 3]. targets [2,3,4]. targets [batch_size, 3]\n",
        "        targets_flat = targets.reshape(-1) #targets_flat [batch_size * seq_length]\n",
        "\n",
        "        # Predict items\n",
        "        output = model(inputs, session_data)\n",
        "        output_flat = output.reshape(-1, config['num_items']) # output_flat: [768, 8423] [batch_size *3, num_items]\n",
        "\n",
        "        # Backpropogation process\n",
        "        loss = criterion(output_flat, targets_flat)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        # Results\n",
        "        if i % log_interval == 0 and i > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            ppl = math.exp(cur_loss)\n",
        "            print(f'| epoch {epoch:3d} '\n",
        "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
        "            total_loss = 0\n",
        "            start_time = time.time()"
      ],
      "metadata": {
        "id": "dbYBAVL8bNrr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation"
      ],
      "metadata": {
        "id": "dDnxSIldExkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation metric"
      ],
      "metadata": {
        "id": "9yPShjpJ3DWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation metrics\n",
        "\n",
        "def recall_metric(indices, targets):\n",
        "  \"\"\"\n",
        "  Inputs: indices: [batch, top_k] indices of top_k items predicted\n",
        "          targets: [batch, (seq_len-1: ex: 3)] targets items in the sequences\n",
        "  Output: how many targets in indices\n",
        "\n",
        "  \"\"\"\n",
        "  recall = 0\n",
        "  check_recall_masked = torch.isin(indices, targets)\n",
        "  check_recall_count = check_recall_masked.double()\n",
        "  check_hits = torch.sum(check_recall_count) #return a torch.tensor([value.])\n",
        "  hits = check_hits.item() #return an integer\n",
        "\n",
        "  n = indices.numel() #return a total number of matrix targets\n",
        "\n",
        "  recall = hits/n\n",
        "  return recall"
      ],
      "metadata": {
        "id": "9IT5meMazyAj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_indices = torch.tensor([[2773, 136, 14, 56,77,88, 100, 89],\n",
        "                             [612, 20, 26, 22, 2026, 67, 12 ,14]])\n",
        "d_targets = torch.tensor([[2, 1], [20, 52]])"
      ],
      "metadata": {
        "id": "YB18i4md1f-y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_recall20 = recall_metric(indices = c_indices, targets = d_targets)\n",
        "print(check_recall20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SYIIt1H1FyR",
        "outputId": "2dc86440-700a-4915-cce8-3304222bd378"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation"
      ],
      "metadata": {
        "id": "l7UvSMsz3S4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
        "    model.eval()\n",
        "    total_loss = 0.\n",
        "\n",
        "    RECALL = []\n",
        "    with torch.no_grad():\n",
        "        for i, (item_data, session_data) in enumerate(eval_data):\n",
        "            # Load item sequence and session id\n",
        "            item_data, session_data = item_data.to(device), session_data.to(device)\n",
        "            session_data = session_data.reshape(-1, 1)\n",
        "            # Split item sequence to inputs and targets\n",
        "            inputs, targets = item_data[:, :-1], item_data[:, 1:]  #if max = 4: inputs[1,2,3]. Inputs [batch_size, 3]. targets [2,3,4]. targets [batch_size, 3]\n",
        "            targets_flat = targets.reshape(-1)\n",
        "            # Predict items\n",
        "            output = model(inputs, session_data)\n",
        "            output_flat = output.reshape(-1, config['num_items']) # output_flat: [768, 8423] [batch_size *3, num_items]\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(output_flat, targets_flat)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            #Get predictions\n",
        "            targets_flat = targets.reshape(-1) #targets_flat [batch_size*3]. Ex: [768]\n",
        "            # Reshape the output_flat to get top predictions\n",
        "            outputs = output_flat.reshape(output_flat.shape[0] // inputs.shape[1],\n",
        "                                          inputs.shape[1],\n",
        "                                          output_flat.shape[1])[: , -1, :] #outputs: [batch, num_items]\n",
        "            #values, indices = outputs.topk(k + inputs.shape[1], dim=-1) #dim = -1 sort\n",
        "            values, indices = outputs.topk(k = config['topk'], dim=-1)\n",
        "\n",
        "            #Evaluation\n",
        "            recall = recall_metric(indices = indices, targets = targets)\n",
        "            RECALL.append(recall)\n",
        "\n",
        "    recall_avg = sum(RECALL)/len(RECALL)\n",
        "    return total_loss / (len(eval_data) - 1), recall_avg"
      ],
      "metadata": {
        "id": "9tgDtGXIbk4x"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "epochs = config['epochs']\n",
        "\n",
        "with TemporaryDirectory() as tempdir:\n",
        "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        # Training\n",
        "        train(model, train_iter, epoch)\n",
        "\n",
        "        # Evaluation\n",
        "        val_loss, recall_avg = evaluate(model, val_iter)\n",
        "\n",
        "        # Compute the perplexity of the validation loss\n",
        "        val_ppl = math.exp(val_loss)\n",
        "        elapsed = time.time() - epoch_start_time\n",
        "\n",
        "        # Results\n",
        "        print('-' * 89)\n",
        "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}  | '\n",
        "            f'recall_avg {recall_avg}')\n",
        "        print('-' * 89)\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "        scheduler.step()\n",
        "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMjCAlZ-bzBM",
        "outputId": "7ff58b79-b257-458c-88a2-56530b4427ef"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 lr 0.10 | ms/batch 931.25 | loss  7.97 | ppl  2884.33\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 368.33s | valid loss  8.00 | valid ppl  2995.73  | recall_avg 0.45532275800945365\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 lr 0.10 | ms/batch 913.61 | loss  7.89 | ppl  2679.26\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 363.85s | valid loss  7.96 | valid ppl  2858.20  | recall_avg 0.47291910123424374\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 lr 0.09 | ms/batch 921.87 | loss  7.85 | ppl  2562.75\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 364.76s | valid loss  7.93 | valid ppl  2784.72  | recall_avg 0.46764476102941166\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 lr 0.09 | ms/batch 914.17 | loss  7.81 | ppl  2457.38\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 363.69s | valid loss  7.91 | valid ppl  2726.06  | recall_avg 0.4553144695378151\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 lr 0.08 | ms/batch 910.41 | loss  7.77 | ppl  2379.65\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 362.46s | valid loss  7.90 | valid ppl  2693.62  | recall_avg 0.44827714679621855\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}